{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ce03286",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tree\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdecimal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Decimal\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset, DataLoader,TensorDataset\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "import os\n",
    "import torch \n",
    "from decimal import Decimal\n",
    "from torch.utils.data import Dataset, DataLoader,TensorDataset\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing\n",
    "import glob\n",
    "import os\n",
    "import torchattacks\n",
    "\n",
    "from scipy import linalg\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from torch.autograd import Variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c553ce85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv('data_without_ioa.csv')\n",
    "df2=pd.read_csv('data_with_ioa.csv')\n",
    "# df3=pd.read_csv('calss3_generated.csv')\n",
    "# df4=pd.read_csv('calss4_generated.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b88fefe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "714fbf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.drop(columns=df1.columns[0], axis=1, inplace=True)\n",
    "df2.drop(columns=df2.columns[0], axis=1, inplace=True)\n",
    "# df3.drop(columns=df3.columns[0], axis=1, inplace=True)\n",
    "# df4.drop(columns=df4.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df2.drop(['ioa'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df=pd.concat([df1,df2])\n",
    "for i in ['oa']: #'fmt','numix',\n",
    "    df.drop([i], axis=1, inplace=True)\n",
    "\n",
    "# df=pd.concat([df_int])\n",
    "    \n",
    "# df.drop(['dstIP','srcIP','oa'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "912b39a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[df['label']!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfad741f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8     38178\n",
       "11    37363\n",
       "10    25832\n",
       "7     10861\n",
       "2      3177\n",
       "1      2289\n",
       "4      1344\n",
       "5      1270\n",
       "6       964\n",
       "3       499\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1ae30e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#majority under sampling\n",
    "# df\n",
    "# data=df[df['label']!=0]\n",
    "# data_s = resample(df[df['label']==0], replace=False,n_samples=10000,random_state=123)\n",
    "# df=pd.concat([data,data_s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bf729bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#All sampling\n",
    "data_train_sampled=pd.DataFrame([],columns=df.columns.values,dtype=float)\n",
    "sampling=5000\n",
    "for i in df['label'].unique():\n",
    "    if i==1:\n",
    "        data_s = resample(df[df['label']==i], replace=True,n_samples=int(sampling*2),random_state=123)\n",
    "        data_train_sampled=pd.concat([data_train_sampled,data_s])\n",
    "        \n",
    "#     if i==1:\n",
    "#         data_s = resample(df[df['label']==i], replace=True,n_samples=int(sampling*2),random_state=123)\n",
    "#         data_train_sampled=pd.concat([data_train_sampled,data_s])\n",
    "        \n",
    "#     elif i==2:\n",
    "#         data_s = resample(df[df['label']==i], replace=True,n_samples=int(sampling*2),random_state=123)\n",
    "#         data_train_sampled=pd.concat([data_train_sampled,data_s])\n",
    "        \n",
    "#     elif i==3:\n",
    "#         data_s = resample(df[df['label']==i], replace=True,n_samples=int(sampling*2),random_state=123)\n",
    "#         data_train_sampled=pd.concat([data_train_sampled,data_s])\n",
    "        \n",
    "        \n",
    "    elif i==4:\n",
    "        data_s = resample(df[df['label']==i], replace=True,n_samples=int(sampling*2),random_state=123)\n",
    "        data_train_sampled=pd.concat([data_train_sampled,data_s])\n",
    "        \n",
    "#     elif i==5:\n",
    "#         data_s = resample(df[df['label']==i], replace=True,n_samples=int(sampling*2),random_state=123)\n",
    "#         data_train_sampled=pd.concat([data_train_sampled,data_s])\n",
    "        \n",
    "         \n",
    "#     elif i==6:\n",
    "#         data_s = resample(df[df['label']==i], replace=True,n_samples=int(sampling*2),random_state=123)\n",
    "#         data_train_sampled=pd.concat([data_train_sampled,data_s])\n",
    "    \n",
    "    elif df[df['label']==i].shape[0]>sampling:\n",
    "        \n",
    "        data_s = resample(df[df['label']==i], replace=False,n_samples=sampling,random_state=123)\n",
    "        data_train_sampled=pd.concat([data_train_sampled,data_s])\n",
    "    \n",
    "    else:\n",
    "        data_s = resample(df[df['label']==i], replace=True,n_samples=sampling,random_state=123) \n",
    "        data_train_sampled=pd.concat([data_train_sampled,data_s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f91d2637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X,y = df.iloc[:, :-1], df.iloc[:, [-1]]\n",
    "X, y = data_train_sampled.iloc[:, :-1], data_train_sampled.iloc[:, [-1]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afdfd5bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TimeStamp</th>\n",
       "      <th>Relative Time</th>\n",
       "      <th>srcIP</th>\n",
       "      <th>dstIP</th>\n",
       "      <th>srcPort</th>\n",
       "      <th>dstPort</th>\n",
       "      <th>ipLen</th>\n",
       "      <th>len</th>\n",
       "      <th>fmt</th>\n",
       "      <th>uType</th>\n",
       "      <th>asduType</th>\n",
       "      <th>numix</th>\n",
       "      <th>cot</th>\n",
       "      <th>addr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>538929</th>\n",
       "      <td>6.341554</td>\n",
       "      <td>72303.158509</td>\n",
       "      <td>3.232236e+09</td>\n",
       "      <td>3.232236e+09</td>\n",
       "      <td>2404.0</td>\n",
       "      <td>42126.0</td>\n",
       "      <td>748.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537139</th>\n",
       "      <td>6.204554</td>\n",
       "      <td>71493.153248</td>\n",
       "      <td>3.232236e+09</td>\n",
       "      <td>3.232236e+09</td>\n",
       "      <td>2404.0</td>\n",
       "      <td>42126.0</td>\n",
       "      <td>748.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536302</th>\n",
       "      <td>6.142552</td>\n",
       "      <td>71113.132922</td>\n",
       "      <td>3.232236e+09</td>\n",
       "      <td>3.232236e+09</td>\n",
       "      <td>2404.0</td>\n",
       "      <td>42126.0</td>\n",
       "      <td>748.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536889</th>\n",
       "      <td>6.184559</td>\n",
       "      <td>71373.209308</td>\n",
       "      <td>3.232236e+09</td>\n",
       "      <td>3.232236e+09</td>\n",
       "      <td>42126.0</td>\n",
       "      <td>2404.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470455</th>\n",
       "      <td>20.592457</td>\n",
       "      <td>37812.185928</td>\n",
       "      <td>3.232236e+09</td>\n",
       "      <td>3.232236e+09</td>\n",
       "      <td>42126.0</td>\n",
       "      <td>2404.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400028</th>\n",
       "      <td>21.172180</td>\n",
       "      <td>196544.801946</td>\n",
       "      <td>3.232238e+09</td>\n",
       "      <td>3.232239e+09</td>\n",
       "      <td>61254.0</td>\n",
       "      <td>2404.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359019</th>\n",
       "      <td>21.150775</td>\n",
       "      <td>23610.752056</td>\n",
       "      <td>3.232239e+09</td>\n",
       "      <td>3.232238e+09</td>\n",
       "      <td>2404.0</td>\n",
       "      <td>61254.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>65535.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399941</th>\n",
       "      <td>21.112408</td>\n",
       "      <td>196187.080964</td>\n",
       "      <td>3.232238e+09</td>\n",
       "      <td>3.232239e+09</td>\n",
       "      <td>61254.0</td>\n",
       "      <td>2404.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400002</th>\n",
       "      <td>21.153406</td>\n",
       "      <td>196437.068365</td>\n",
       "      <td>3.232239e+09</td>\n",
       "      <td>3.232238e+09</td>\n",
       "      <td>2404.0</td>\n",
       "      <td>61254.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>65535.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357639</th>\n",
       "      <td>19.394783</td>\n",
       "      <td>17890.833311</td>\n",
       "      <td>3.232239e+09</td>\n",
       "      <td>3.232238e+09</td>\n",
       "      <td>2404.0</td>\n",
       "      <td>61254.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>65535.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        TimeStamp  Relative Time         srcIP         dstIP  srcPort  \\\n",
       "538929   6.341554   72303.158509  3.232236e+09  3.232236e+09   2404.0   \n",
       "537139   6.204554   71493.153248  3.232236e+09  3.232236e+09   2404.0   \n",
       "536302   6.142552   71113.132922  3.232236e+09  3.232236e+09   2404.0   \n",
       "536889   6.184559   71373.209308  3.232236e+09  3.232236e+09  42126.0   \n",
       "470455  20.592457   37812.185928  3.232236e+09  3.232236e+09  42126.0   \n",
       "...           ...            ...           ...           ...      ...   \n",
       "400028  21.172180  196544.801946  3.232238e+09  3.232239e+09  61254.0   \n",
       "359019  21.150775   23610.752056  3.232239e+09  3.232238e+09   2404.0   \n",
       "399941  21.112408  196187.080964  3.232238e+09  3.232239e+09  61254.0   \n",
       "400002  21.153406  196437.068365  3.232239e+09  3.232238e+09   2404.0   \n",
       "357639  19.394783   17890.833311  3.232239e+09  3.232238e+09   2404.0   \n",
       "\n",
       "        dstPort  ipLen   len  fmt  uType  asduType  numix   cot     addr  \n",
       "538929  42126.0  748.0  70.0  0.0    1.0      33.0    4.0  20.0     10.0  \n",
       "537139  42126.0  748.0  30.0  0.0    1.0       5.0    4.0  20.0     10.0  \n",
       "536302  42126.0  748.0  26.0  0.0    1.0       3.0    4.0  20.0     10.0  \n",
       "536889   2404.0   76.0   4.0  1.0    1.0      31.0    4.0  20.0     10.0  \n",
       "470455   2404.0   68.0  14.0  0.0    1.0     100.0    1.0   6.0     10.0  \n",
       "...         ...    ...   ...  ...    ...       ...    ...   ...      ...  \n",
       "400028   2404.0   46.0   4.0  2.0    2.0       9.0    1.0   3.0     55.0  \n",
       "359019  61254.0   67.0  25.0  1.0    2.0      36.0    1.0   3.0  65535.0  \n",
       "399941   2404.0   46.0   4.0  2.0    2.0       9.0    1.0   3.0     55.0  \n",
       "400002  61254.0   67.0  25.0  1.0    2.0      36.0    1.0   3.0  65535.0  \n",
       "357639  61254.0   67.0  25.0  1.0    2.0      36.0    1.0   3.0  65535.0  \n",
       "\n",
       "[60000 rows x 14 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57e22054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0     10000\n",
       "4.0     10000\n",
       "7.0      5000\n",
       "8.0      5000\n",
       "10.0     5000\n",
       "11.0     5000\n",
       "2.0      5000\n",
       "3.0      5000\n",
       "5.0      5000\n",
       "6.0      5000\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y['label'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22b855e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amalb\\AppData\\Local\\Temp/ipykernel_31212/1367956840.py:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfc.fit(X, y);\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier();\n",
    "\n",
    "# fit random forest classifier on the training set\n",
    "rfc.fit(X, y);\n",
    "# extract important features\n",
    "score = np.round(rfc.feature_importances_,3)\n",
    "importances = pd.DataFrame({'feature':X.columns,'importance':score})\n",
    "importances = importances.sort_values('importance',ascending=False).set_index('feature')\n",
    "# plot importances\n",
    "plt.rcParams['figure.figsize'] = (11, 4)\n",
    "importances.plot.bar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7fd2f7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'asduType','len'\n",
    "# for i in ['fmt','numix','oa']:\n",
    "#     X.drop([i], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a23d84f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TimeStamp', 'Relative Time', 'srcIP', 'dstIP', 'srcPort', 'dstPort',\n",
       "       'ipLen', 'len', 'fmt', 'uType', 'asduType', 'numix', 'cot', 'addr'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b9a4789",
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = MinMaxScaler()\n",
    "\n",
    "X_mm = mm.fit_transform(X) \n",
    "\n",
    "\n",
    "df_data=torch.Tensor(X_mm)\n",
    "df_label=y.values[:,0]\n",
    "\n",
    "# y=torch.Tensor(y.values)\n",
    "\n",
    "\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = df_label.reshape(len(df_label), 1)\n",
    "encoded_label = onehot_encoder.fit_transform(integer_encoded)\n",
    "encoded_label=torch.Tensor(encoded_label)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4802446e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_scaled=pd.DataFrame(X_mm,columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71d48691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd528bbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TimeStamp</th>\n",
       "      <th>Relative Time</th>\n",
       "      <th>srcIP</th>\n",
       "      <th>dstIP</th>\n",
       "      <th>srcPort</th>\n",
       "      <th>dstPort</th>\n",
       "      <th>ipLen</th>\n",
       "      <th>len</th>\n",
       "      <th>fmt</th>\n",
       "      <th>uType</th>\n",
       "      <th>asduType</th>\n",
       "      <th>numix</th>\n",
       "      <th>cot</th>\n",
       "      <th>addr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.248407</td>\n",
       "      <td>0.293191</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000369</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.67497</td>\n",
       "      <td>0.961644</td>\n",
       "      <td>0.265060</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.258065</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.000153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.242012</td>\n",
       "      <td>0.289867</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000369</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.67497</td>\n",
       "      <td>0.961644</td>\n",
       "      <td>0.104418</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.000153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.239118</td>\n",
       "      <td>0.288307</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000369</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.67497</td>\n",
       "      <td>0.961644</td>\n",
       "      <td>0.088353</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.016129</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.000153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.241079</td>\n",
       "      <td>0.289374</td>\n",
       "      <td>0.000369</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.67497</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.041096</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.241935</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.000153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.913646</td>\n",
       "      <td>0.151625</td>\n",
       "      <td>0.000369</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.67497</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.030137</td>\n",
       "      <td>0.040161</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.798387</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>0.000153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>0.940708</td>\n",
       "      <td>0.803135</td>\n",
       "      <td>0.949409</td>\n",
       "      <td>0.999262</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>0.939709</td>\n",
       "      <td>0.093335</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.948708</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.028767</td>\n",
       "      <td>0.084337</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.282258</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>0.937918</td>\n",
       "      <td>0.801667</td>\n",
       "      <td>0.949409</td>\n",
       "      <td>0.999262</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>0.939832</td>\n",
       "      <td>0.802693</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.948708</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.028767</td>\n",
       "      <td>0.084337</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.282258</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>0.857738</td>\n",
       "      <td>0.069858</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.948708</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.028767</td>\n",
       "      <td>0.084337</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.282258</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       TimeStamp  Relative Time     srcIP     dstIP  srcPort  dstPort  \\\n",
       "0       0.248407       0.293191  0.000000  0.000369  0.00000  0.67497   \n",
       "1       0.242012       0.289867  0.000000  0.000369  0.00000  0.67497   \n",
       "2       0.239118       0.288307  0.000000  0.000369  0.00000  0.67497   \n",
       "3       0.241079       0.289374  0.000369  0.000000  0.67497  0.00000   \n",
       "4       0.913646       0.151625  0.000369  0.000000  0.67497  0.00000   \n",
       "...          ...            ...       ...       ...      ...      ...   \n",
       "59995   0.940708       0.803135  0.949409  0.999262  1.00000  0.00000   \n",
       "59996   0.939709       0.093335  1.000000  0.948708  0.00000  1.00000   \n",
       "59997   0.937918       0.801667  0.949409  0.999262  1.00000  0.00000   \n",
       "59998   0.939832       0.802693  1.000000  0.948708  0.00000  1.00000   \n",
       "59999   0.857738       0.069858  1.000000  0.948708  0.00000  1.00000   \n",
       "\n",
       "          ipLen       len  fmt     uType  asduType  numix       cot      addr  \n",
       "0      0.961644  0.265060  0.0  0.333333  0.258065    1.0  0.386364  0.000153  \n",
       "1      0.961644  0.104418  0.0  0.333333  0.032258    1.0  0.386364  0.000153  \n",
       "2      0.961644  0.088353  0.0  0.333333  0.016129    1.0  0.386364  0.000153  \n",
       "3      0.041096  0.000000  0.5  0.333333  0.241935    1.0  0.386364  0.000153  \n",
       "4      0.030137  0.040161  0.0  0.333333  0.798387    0.0  0.068182  0.000153  \n",
       "...         ...       ...  ...       ...       ...    ...       ...       ...  \n",
       "59995  0.000000  0.000000  1.0  0.666667  0.064516    0.0  0.000000  0.000839  \n",
       "59996  0.028767  0.084337  0.5  0.666667  0.282258    0.0  0.000000  1.000000  \n",
       "59997  0.000000  0.000000  1.0  0.666667  0.064516    0.0  0.000000  0.000839  \n",
       "59998  0.028767  0.084337  0.5  0.666667  0.282258    0.0  0.000000  1.000000  \n",
       "59999  0.028767  0.084337  0.5  0.666667  0.282258    0.0  0.000000  1.000000  \n",
       "\n",
       "[60000 rows x 14 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3bb2a24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_data, encoded_label, test_size=0.3,random_state=109) # 70% training and 30% test\n",
    "# X_train = X_train.unsqueeze(1)\n",
    "# X_test = X_test.unsqueeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e6bdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d727c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(X_train, y_train)\n",
    "test_data = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=2000)#train_data.tensors[0].shape[0])\n",
    "test_loader = DataLoader(test_data, batch_size=test_data.tensors[0].shape[0])\n",
    "\n",
    "# print(\"Training data batches:\")\n",
    "# for X, y in train_loader:\n",
    "#     print(X.shape, y.shape)\n",
    "    \n",
    "# print(\"\\nTest data batches:\")\n",
    "# for X, y in test_loader:\n",
    "#     print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6dff87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_f=train_data.tensors[0].shape[1]\n",
    "out_f=train_data.tensors[1].shape[1]\n",
    "\n",
    "class MulticlassClassification(nn.Module):\n",
    "    def __init__(self, num_feature, num_class):\n",
    "        super(MulticlassClassification, self).__init__()\n",
    "        \n",
    "\n",
    "        \n",
    "        self.layer_1 = nn.Linear(num_feature, 512)\n",
    "        self.layer_2 = nn.Linear(512, 256)\n",
    "        self.layer_3 = nn.Linear(256, 128)\n",
    "        self.layer_4 = nn.Linear(128, 32)\n",
    "\n",
    "        self.layer_out = nn.Linear(32, num_class) \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(512)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(256)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(128)\n",
    "        self.batchnorm4 = nn.BatchNorm1d(32)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        \n",
    "        x = self.layer_1(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.layer_2(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.layer_3(x)\n",
    "        x = self.batchnorm3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.layer_4(x)\n",
    "        x = self.batchnorm4(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.layer_out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "96ed8f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(14, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(128 * 4, 512)\n",
    "        self.fc2 = nn.Linear(512, 11)\n",
    "\n",
    "    def forward(self, x):\n",
    "            \n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 128 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e0854dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MulticlassClassification(num_feature = in_f, num_class=out_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5b13e99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch(loader, model,loss_function,optimizer):\n",
    "    for X, y in loader:\n",
    "#         X=X.reshape(1, 1000, 14)\n",
    "#         print(y)\n",
    "        #X = X[:, :, :14]\n",
    "#         y = y.reshape(-1)\n",
    "        \n",
    "        preds = model(X)\n",
    "        \n",
    "        preds=torch.softmax(preds,axis=1)\n",
    "        \n",
    "        loss = loss_function(preds, torch.max(y, 1)[1])\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        y_labels=torch.argmax(y,axis=1)\n",
    "        pred_labels=torch.argmax(preds,axis=1)\n",
    "        \n",
    "        acc=100 * torch.mean((pred_labels == y_labels).float()).item()\n",
    "        #     print(metrics.classification_report(y_labels, pred_labels))\n",
    "\n",
    "        \n",
    "    return loss,acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "930713cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>538929</th>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537139</th>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536302</th>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536889</th>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470455</th>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400028</th>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359019</th>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399941</th>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400002</th>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357639</th>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        label\n",
       "538929    7.0\n",
       "537139    7.0\n",
       "536302    7.0\n",
       "536889    7.0\n",
       "470455    7.0\n",
       "...       ...\n",
       "400028    6.0\n",
       "359019    6.0\n",
       "399941    6.0\n",
       "400002    6.0\n",
       "357639    6.0\n",
       "\n",
       "[60000 rows x 1 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6928847a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400, Loss: 1.468, Accuracy: 99.400\n",
      "Epoch 2/400, Loss: 1.463, Accuracy: 99.900\n",
      "Epoch 3/400, Loss: 1.463, Accuracy: 99.900\n",
      "Epoch 4/400, Loss: 1.468, Accuracy: 99.350\n",
      "Epoch 5/400, Loss: 1.485, Accuracy: 97.700\n",
      "Epoch 6/400, Loss: 1.492, Accuracy: 96.950\n",
      "Epoch 7/400, Loss: 1.482, Accuracy: 97.900\n",
      "Epoch 8/400, Loss: 1.489, Accuracy: 97.250\n",
      "Epoch 9/400, Loss: 1.489, Accuracy: 97.200\n",
      "Epoch 10/400, Loss: 1.488, Accuracy: 97.300\n",
      "Epoch 11/400, Loss: 1.493, Accuracy: 96.800\n",
      "Epoch 12/400, Loss: 1.492, Accuracy: 97.000\n",
      "Epoch 13/400, Loss: 1.481, Accuracy: 98.050\n",
      "Epoch 14/400, Loss: 1.487, Accuracy: 97.450\n",
      "Epoch 15/400, Loss: 1.474, Accuracy: 98.750\n",
      "Epoch 16/400, Loss: 1.495, Accuracy: 96.650\n",
      "Epoch 17/400, Loss: 1.485, Accuracy: 97.700\n",
      "Epoch 18/400, Loss: 1.490, Accuracy: 97.150\n",
      "Epoch 19/400, Loss: 1.490, Accuracy: 97.150\n",
      "Epoch 20/400, Loss: 1.486, Accuracy: 97.550\n",
      "Epoch 21/400, Loss: 1.490, Accuracy: 97.100\n",
      "Epoch 22/400, Loss: 1.485, Accuracy: 97.600\n",
      "Epoch 23/400, Loss: 1.483, Accuracy: 97.800\n",
      "Epoch 24/400, Loss: 1.484, Accuracy: 97.750\n",
      "Epoch 25/400, Loss: 1.484, Accuracy: 97.750\n",
      "Epoch 26/400, Loss: 1.483, Accuracy: 97.850\n",
      "Epoch 27/400, Loss: 1.483, Accuracy: 97.850\n",
      "Epoch 28/400, Loss: 1.486, Accuracy: 97.500\n",
      "Epoch 29/400, Loss: 1.489, Accuracy: 97.250\n",
      "Epoch 30/400, Loss: 1.482, Accuracy: 97.950\n",
      "Epoch 31/400, Loss: 1.489, Accuracy: 97.200\n",
      "Epoch 32/400, Loss: 1.485, Accuracy: 97.650\n",
      "Epoch 33/400, Loss: 1.482, Accuracy: 97.900\n",
      "Epoch 34/400, Loss: 1.485, Accuracy: 97.650\n",
      "Epoch 35/400, Loss: 1.488, Accuracy: 97.300\n",
      "Epoch 36/400, Loss: 1.482, Accuracy: 97.900\n",
      "Epoch 37/400, Loss: 1.491, Accuracy: 97.000\n",
      "Epoch 38/400, Loss: 1.491, Accuracy: 97.000\n",
      "Epoch 39/400, Loss: 1.490, Accuracy: 97.150\n",
      "Epoch 40/400, Loss: 1.486, Accuracy: 97.550\n",
      "Epoch 41/400, Loss: 1.485, Accuracy: 97.600\n",
      "Epoch 42/400, Loss: 1.497, Accuracy: 96.400\n",
      "Epoch 43/400, Loss: 1.486, Accuracy: 97.500\n",
      "Epoch 44/400, Loss: 1.489, Accuracy: 97.200\n",
      "Epoch 45/400, Loss: 1.485, Accuracy: 97.600\n",
      "Epoch 46/400, Loss: 1.488, Accuracy: 97.300\n",
      "Epoch 47/400, Loss: 1.485, Accuracy: 97.600\n",
      "Epoch 48/400, Loss: 1.488, Accuracy: 97.350\n",
      "Epoch 49/400, Loss: 1.481, Accuracy: 98.000\n",
      "Epoch 50/400, Loss: 1.488, Accuracy: 97.350\n",
      "Epoch 51/400, Loss: 1.490, Accuracy: 97.100\n",
      "Epoch 52/400, Loss: 1.489, Accuracy: 97.250\n",
      "Epoch 53/400, Loss: 1.487, Accuracy: 97.450\n",
      "Epoch 54/400, Loss: 1.497, Accuracy: 96.500\n",
      "Epoch 55/400, Loss: 1.491, Accuracy: 97.050\n",
      "Epoch 56/400, Loss: 1.490, Accuracy: 97.100\n",
      "Epoch 57/400, Loss: 1.501, Accuracy: 96.050\n",
      "Epoch 58/400, Loss: 1.493, Accuracy: 96.800\n",
      "Epoch 59/400, Loss: 1.486, Accuracy: 97.550\n",
      "Epoch 60/400, Loss: 1.489, Accuracy: 97.250\n",
      "Epoch 61/400, Loss: 1.483, Accuracy: 97.800\n",
      "Epoch 62/400, Loss: 1.492, Accuracy: 96.900\n",
      "Epoch 63/400, Loss: 1.489, Accuracy: 97.150\n",
      "Epoch 64/400, Loss: 1.485, Accuracy: 97.600\n",
      "Epoch 65/400, Loss: 1.492, Accuracy: 96.900\n",
      "Epoch 66/400, Loss: 1.483, Accuracy: 97.850\n",
      "Epoch 67/400, Loss: 1.488, Accuracy: 97.350\n",
      "Epoch 68/400, Loss: 1.490, Accuracy: 97.100\n",
      "Epoch 69/400, Loss: 1.485, Accuracy: 97.650\n",
      "Epoch 70/400, Loss: 1.480, Accuracy: 98.150\n",
      "Epoch 71/400, Loss: 1.488, Accuracy: 97.300\n",
      "Epoch 72/400, Loss: 1.491, Accuracy: 97.050\n",
      "Epoch 73/400, Loss: 1.487, Accuracy: 97.450\n",
      "Epoch 74/400, Loss: 1.487, Accuracy: 97.400\n",
      "Epoch 75/400, Loss: 1.487, Accuracy: 97.400\n",
      "Epoch 76/400, Loss: 1.488, Accuracy: 97.300\n",
      "Epoch 77/400, Loss: 1.487, Accuracy: 97.400\n",
      "Epoch 78/400, Loss: 1.488, Accuracy: 97.350\n",
      "Epoch 79/400, Loss: 1.488, Accuracy: 97.350\n",
      "Epoch 80/400, Loss: 1.489, Accuracy: 97.200\n",
      "Epoch 81/400, Loss: 1.493, Accuracy: 96.850\n",
      "Epoch 82/400, Loss: 1.499, Accuracy: 96.250\n",
      "Epoch 83/400, Loss: 1.490, Accuracy: 97.100\n",
      "Epoch 84/400, Loss: 1.487, Accuracy: 97.450\n",
      "Epoch 85/400, Loss: 1.486, Accuracy: 97.550\n",
      "Epoch 86/400, Loss: 1.491, Accuracy: 97.000\n",
      "Epoch 87/400, Loss: 1.486, Accuracy: 97.550\n",
      "Epoch 88/400, Loss: 1.482, Accuracy: 97.950\n",
      "Epoch 89/400, Loss: 1.490, Accuracy: 97.150\n",
      "Epoch 90/400, Loss: 1.488, Accuracy: 97.300\n",
      "Epoch 91/400, Loss: 1.487, Accuracy: 97.400\n",
      "Epoch 92/400, Loss: 1.483, Accuracy: 97.850\n",
      "Epoch 93/400, Loss: 1.483, Accuracy: 97.800\n",
      "Epoch 94/400, Loss: 1.485, Accuracy: 97.600\n",
      "Epoch 95/400, Loss: 1.488, Accuracy: 97.350\n",
      "Epoch 96/400, Loss: 1.490, Accuracy: 97.100\n",
      "Epoch 97/400, Loss: 1.491, Accuracy: 97.050\n",
      "Epoch 98/400, Loss: 1.489, Accuracy: 97.250\n",
      "Epoch 99/400, Loss: 1.488, Accuracy: 97.350\n",
      "Epoch 100/400, Loss: 1.492, Accuracy: 96.950\n",
      "Epoch 101/400, Loss: 1.484, Accuracy: 97.750\n",
      "Epoch 102/400, Loss: 1.488, Accuracy: 97.300\n",
      "Epoch 103/400, Loss: 1.488, Accuracy: 97.300\n",
      "Epoch 104/400, Loss: 1.498, Accuracy: 96.350\n",
      "Epoch 105/400, Loss: 1.484, Accuracy: 97.700\n",
      "Epoch 106/400, Loss: 1.487, Accuracy: 97.400\n",
      "Epoch 107/400, Loss: 1.482, Accuracy: 97.900\n",
      "Epoch 108/400, Loss: 1.465, Accuracy: 99.600\n",
      "Epoch 109/400, Loss: 1.489, Accuracy: 97.150\n",
      "Epoch 110/400, Loss: 1.489, Accuracy: 97.250\n",
      "Epoch 111/400, Loss: 1.487, Accuracy: 97.500\n",
      "Epoch 112/400, Loss: 1.486, Accuracy: 97.550\n",
      "Epoch 113/400, Loss: 1.492, Accuracy: 96.950\n",
      "Epoch 114/400, Loss: 1.489, Accuracy: 97.250\n",
      "Epoch 115/400, Loss: 1.490, Accuracy: 97.100\n",
      "Epoch 116/400, Loss: 1.484, Accuracy: 97.750\n",
      "Epoch 117/400, Loss: 1.492, Accuracy: 96.950\n",
      "Epoch 118/400, Loss: 1.484, Accuracy: 97.700\n",
      "Epoch 119/400, Loss: 1.488, Accuracy: 97.350\n",
      "Epoch 120/400, Loss: 1.490, Accuracy: 97.150\n",
      "Epoch 121/400, Loss: 1.486, Accuracy: 97.500\n",
      "Epoch 122/400, Loss: 1.494, Accuracy: 96.750\n",
      "Epoch 123/400, Loss: 1.487, Accuracy: 97.450\n",
      "Epoch 124/400, Loss: 1.478, Accuracy: 98.350\n",
      "Epoch 125/400, Loss: 1.492, Accuracy: 96.900\n",
      "Epoch 126/400, Loss: 1.489, Accuracy: 97.200\n",
      "Epoch 127/400, Loss: 1.486, Accuracy: 97.550\n",
      "Epoch 128/400, Loss: 1.493, Accuracy: 96.850\n",
      "Epoch 129/400, Loss: 1.491, Accuracy: 97.050\n",
      "Epoch 130/400, Loss: 1.487, Accuracy: 97.400\n",
      "Epoch 131/400, Loss: 1.490, Accuracy: 97.100\n",
      "Epoch 132/400, Loss: 1.490, Accuracy: 97.100\n",
      "Epoch 133/400, Loss: 1.484, Accuracy: 97.750\n",
      "Epoch 134/400, Loss: 1.486, Accuracy: 97.550\n",
      "Epoch 135/400, Loss: 1.484, Accuracy: 97.700\n",
      "Epoch 136/400, Loss: 1.488, Accuracy: 97.300\n",
      "Epoch 137/400, Loss: 1.481, Accuracy: 98.000\n",
      "Epoch 138/400, Loss: 1.487, Accuracy: 97.450\n",
      "Epoch 139/400, Loss: 1.486, Accuracy: 97.550\n",
      "Epoch 140/400, Loss: 1.486, Accuracy: 97.550\n",
      "Epoch 141/400, Loss: 1.490, Accuracy: 97.100\n",
      "Epoch 142/400, Loss: 1.490, Accuracy: 97.100\n",
      "Epoch 143/400, Loss: 1.499, Accuracy: 96.250\n",
      "Epoch 144/400, Loss: 1.485, Accuracy: 97.600\n",
      "Epoch 145/400, Loss: 1.485, Accuracy: 97.600\n",
      "Epoch 146/400, Loss: 1.484, Accuracy: 97.700\n",
      "Epoch 147/400, Loss: 1.495, Accuracy: 96.600\n",
      "Epoch 148/400, Loss: 1.489, Accuracy: 97.200\n",
      "Epoch 149/400, Loss: 1.491, Accuracy: 97.050\n",
      "Epoch 150/400, Loss: 1.491, Accuracy: 97.050\n",
      "Epoch 151/400, Loss: 1.521, Accuracy: 94.000\n",
      "Epoch 152/400, Loss: 1.489, Accuracy: 97.200\n",
      "Epoch 153/400, Loss: 1.493, Accuracy: 96.850\n",
      "Epoch 154/400, Loss: 1.494, Accuracy: 96.800\n",
      "Epoch 155/400, Loss: 1.486, Accuracy: 97.550\n",
      "Epoch 156/400, Loss: 1.491, Accuracy: 97.050\n",
      "Epoch 157/400, Loss: 1.493, Accuracy: 96.850\n",
      "Epoch 158/400, Loss: 1.480, Accuracy: 98.100\n",
      "Epoch 159/400, Loss: 1.481, Accuracy: 98.000\n",
      "Epoch 160/400, Loss: 1.495, Accuracy: 96.600\n",
      "Epoch 161/400, Loss: 1.485, Accuracy: 97.650\n",
      "Epoch 162/400, Loss: 1.491, Accuracy: 97.050\n",
      "Epoch 163/400, Loss: 1.487, Accuracy: 97.450\n",
      "Epoch 164/400, Loss: 1.483, Accuracy: 97.850\n",
      "Epoch 165/400, Loss: 1.490, Accuracy: 97.150\n",
      "Epoch 166/400, Loss: 1.488, Accuracy: 97.350\n",
      "Epoch 167/400, Loss: 1.486, Accuracy: 97.500\n",
      "Epoch 168/400, Loss: 1.491, Accuracy: 97.000\n",
      "Epoch 169/400, Loss: 1.483, Accuracy: 97.800\n",
      "Epoch 170/400, Loss: 1.481, Accuracy: 98.050\n",
      "Epoch 171/400, Loss: 1.485, Accuracy: 97.600\n",
      "Epoch 172/400, Loss: 1.491, Accuracy: 97.000\n",
      "Epoch 173/400, Loss: 1.494, Accuracy: 96.750\n",
      "Epoch 174/400, Loss: 1.495, Accuracy: 96.600\n",
      "Epoch 175/400, Loss: 1.484, Accuracy: 97.700\n",
      "Epoch 176/400, Loss: 1.487, Accuracy: 97.450\n",
      "Epoch 177/400, Loss: 1.485, Accuracy: 97.650\n",
      "Epoch 178/400, Loss: 1.486, Accuracy: 97.500\n",
      "Epoch 179/400, Loss: 1.487, Accuracy: 97.400\n",
      "Epoch 180/400, Loss: 1.484, Accuracy: 97.700\n",
      "Epoch 181/400, Loss: 1.491, Accuracy: 97.000\n",
      "Epoch 182/400, Loss: 1.494, Accuracy: 96.750\n",
      "Epoch 183/400, Loss: 1.488, Accuracy: 97.350\n",
      "Epoch 184/400, Loss: 1.487, Accuracy: 97.400\n",
      "Epoch 185/400, Loss: 1.491, Accuracy: 97.050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 186/400, Loss: 1.489, Accuracy: 97.200\n",
      "Epoch 187/400, Loss: 1.486, Accuracy: 97.500\n",
      "Epoch 188/400, Loss: 1.487, Accuracy: 97.400\n",
      "Epoch 189/400, Loss: 1.487, Accuracy: 97.400\n",
      "Epoch 190/400, Loss: 1.484, Accuracy: 97.750\n",
      "Epoch 191/400, Loss: 1.494, Accuracy: 96.750\n",
      "Epoch 192/400, Loss: 1.484, Accuracy: 97.750\n",
      "Epoch 193/400, Loss: 1.488, Accuracy: 97.300\n",
      "Epoch 194/400, Loss: 1.489, Accuracy: 97.200\n",
      "Epoch 195/400, Loss: 1.485, Accuracy: 97.600\n",
      "Epoch 196/400, Loss: 1.488, Accuracy: 97.350\n",
      "Epoch 197/400, Loss: 1.487, Accuracy: 97.400\n",
      "Epoch 198/400, Loss: 1.490, Accuracy: 97.150\n",
      "Epoch 199/400, Loss: 1.482, Accuracy: 97.900\n",
      "Epoch 200/400, Loss: 1.489, Accuracy: 97.200\n",
      "Epoch 201/400, Loss: 1.487, Accuracy: 97.400\n",
      "Epoch 202/400, Loss: 1.485, Accuracy: 97.650\n",
      "Epoch 203/400, Loss: 1.484, Accuracy: 97.750\n",
      "Epoch 204/400, Loss: 1.493, Accuracy: 96.800\n",
      "Epoch 205/400, Loss: 1.490, Accuracy: 97.150\n",
      "Epoch 206/400, Loss: 1.496, Accuracy: 96.550\n",
      "Epoch 207/400, Loss: 1.484, Accuracy: 97.700\n",
      "Epoch 208/400, Loss: 1.485, Accuracy: 97.650\n",
      "Epoch 209/400, Loss: 1.496, Accuracy: 96.550\n",
      "Epoch 210/400, Loss: 1.488, Accuracy: 97.300\n",
      "Epoch 211/400, Loss: 1.489, Accuracy: 97.250\n",
      "Epoch 212/400, Loss: 1.484, Accuracy: 97.750\n",
      "Epoch 213/400, Loss: 1.485, Accuracy: 97.650\n",
      "Epoch 214/400, Loss: 1.484, Accuracy: 97.700\n",
      "Epoch 215/400, Loss: 1.489, Accuracy: 97.250\n",
      "Epoch 216/400, Loss: 1.488, Accuracy: 97.300\n",
      "Epoch 217/400, Loss: 1.492, Accuracy: 96.900\n",
      "Epoch 218/400, Loss: 1.485, Accuracy: 97.600\n",
      "Epoch 219/400, Loss: 1.487, Accuracy: 97.400\n",
      "Epoch 220/400, Loss: 1.486, Accuracy: 97.500\n",
      "Epoch 221/400, Loss: 1.485, Accuracy: 97.600\n",
      "Epoch 222/400, Loss: 1.487, Accuracy: 97.350\n",
      "Epoch 223/400, Loss: 1.488, Accuracy: 97.300\n",
      "Epoch 224/400, Loss: 1.479, Accuracy: 98.200\n",
      "Epoch 225/400, Loss: 1.489, Accuracy: 97.200\n",
      "Epoch 226/400, Loss: 1.489, Accuracy: 97.250\n",
      "Epoch 227/400, Loss: 1.496, Accuracy: 96.500\n",
      "Epoch 228/400, Loss: 1.485, Accuracy: 97.600\n",
      "Epoch 229/400, Loss: 1.492, Accuracy: 97.000\n",
      "Epoch 230/400, Loss: 1.487, Accuracy: 97.400\n",
      "Epoch 231/400, Loss: 1.493, Accuracy: 96.800\n",
      "Epoch 232/400, Loss: 1.490, Accuracy: 97.100\n",
      "Epoch 233/400, Loss: 1.485, Accuracy: 97.650\n",
      "Epoch 234/400, Loss: 1.488, Accuracy: 97.350\n",
      "Epoch 235/400, Loss: 1.485, Accuracy: 97.650\n",
      "Epoch 236/400, Loss: 1.482, Accuracy: 97.900\n",
      "Epoch 237/400, Loss: 1.485, Accuracy: 97.650\n",
      "Epoch 238/400, Loss: 1.482, Accuracy: 97.900\n",
      "Epoch 239/400, Loss: 1.490, Accuracy: 97.150\n",
      "Epoch 240/400, Loss: 1.493, Accuracy: 96.850\n",
      "Epoch 241/400, Loss: 1.494, Accuracy: 96.750\n",
      "Epoch 242/400, Loss: 1.491, Accuracy: 97.000\n",
      "Epoch 243/400, Loss: 1.482, Accuracy: 97.900\n",
      "Epoch 244/400, Loss: 1.485, Accuracy: 97.600\n",
      "Epoch 245/400, Loss: 1.483, Accuracy: 97.800\n",
      "Epoch 246/400, Loss: 1.487, Accuracy: 97.450\n",
      "Epoch 247/400, Loss: 1.492, Accuracy: 96.950\n",
      "Epoch 248/400, Loss: 1.494, Accuracy: 96.750\n",
      "Epoch 249/400, Loss: 1.493, Accuracy: 96.800\n",
      "Epoch 250/400, Loss: 1.488, Accuracy: 97.350\n",
      "Epoch 251/400, Loss: 1.488, Accuracy: 97.300\n",
      "Epoch 252/400, Loss: 1.489, Accuracy: 97.250\n",
      "Epoch 253/400, Loss: 1.487, Accuracy: 97.450\n",
      "Epoch 254/400, Loss: 1.492, Accuracy: 96.950\n",
      "Epoch 255/400, Loss: 1.484, Accuracy: 97.750\n",
      "Epoch 256/400, Loss: 1.484, Accuracy: 97.750\n",
      "Epoch 257/400, Loss: 1.488, Accuracy: 97.350\n",
      "Epoch 258/400, Loss: 1.486, Accuracy: 97.500\n",
      "Epoch 259/400, Loss: 1.486, Accuracy: 97.550\n",
      "Epoch 260/400, Loss: 1.486, Accuracy: 97.500\n",
      "Epoch 261/400, Loss: 1.486, Accuracy: 97.550\n",
      "Epoch 262/400, Loss: 1.485, Accuracy: 97.650\n",
      "Epoch 263/400, Loss: 1.486, Accuracy: 97.550\n",
      "Epoch 264/400, Loss: 1.485, Accuracy: 97.650\n",
      "Epoch 265/400, Loss: 1.485, Accuracy: 97.600\n",
      "Epoch 266/400, Loss: 1.485, Accuracy: 97.600\n",
      "Epoch 267/400, Loss: 1.489, Accuracy: 97.200\n",
      "Epoch 268/400, Loss: 1.489, Accuracy: 97.250\n",
      "Epoch 269/400, Loss: 1.489, Accuracy: 97.250\n",
      "Epoch 270/400, Loss: 1.484, Accuracy: 97.750\n",
      "Epoch 271/400, Loss: 1.487, Accuracy: 97.400\n",
      "Epoch 272/400, Loss: 1.485, Accuracy: 97.600\n",
      "Epoch 273/400, Loss: 1.487, Accuracy: 97.400\n",
      "Epoch 274/400, Loss: 1.487, Accuracy: 97.450\n",
      "Epoch 275/400, Loss: 1.481, Accuracy: 98.050\n",
      "Epoch 276/400, Loss: 1.488, Accuracy: 97.350\n",
      "Epoch 277/400, Loss: 1.488, Accuracy: 97.300\n",
      "Epoch 278/400, Loss: 1.491, Accuracy: 97.000\n",
      "Epoch 279/400, Loss: 1.484, Accuracy: 97.700\n",
      "Epoch 280/400, Loss: 1.492, Accuracy: 96.900\n",
      "Epoch 281/400, Loss: 1.488, Accuracy: 97.350\n",
      "Epoch 282/400, Loss: 1.486, Accuracy: 97.500\n",
      "Epoch 283/400, Loss: 1.491, Accuracy: 97.050\n",
      "Epoch 284/400, Loss: 1.490, Accuracy: 97.100\n",
      "Epoch 285/400, Loss: 1.480, Accuracy: 98.150\n",
      "Epoch 286/400, Loss: 1.489, Accuracy: 97.250\n",
      "Epoch 287/400, Loss: 1.484, Accuracy: 97.750\n",
      "Epoch 288/400, Loss: 1.484, Accuracy: 97.700\n",
      "Epoch 289/400, Loss: 1.489, Accuracy: 97.200\n",
      "Epoch 290/400, Loss: 1.485, Accuracy: 97.650\n",
      "Epoch 291/400, Loss: 1.482, Accuracy: 97.900\n",
      "Epoch 292/400, Loss: 1.482, Accuracy: 97.900\n",
      "Epoch 293/400, Loss: 1.484, Accuracy: 97.700\n",
      "Epoch 294/400, Loss: 1.490, Accuracy: 97.150\n",
      "Epoch 295/400, Loss: 1.491, Accuracy: 97.000\n",
      "Epoch 296/400, Loss: 1.491, Accuracy: 97.050\n",
      "Epoch 297/400, Loss: 1.485, Accuracy: 97.650\n",
      "Epoch 298/400, Loss: 1.480, Accuracy: 98.150\n",
      "Epoch 299/400, Loss: 1.482, Accuracy: 97.950\n",
      "Epoch 300/400, Loss: 1.483, Accuracy: 97.800\n",
      "Epoch 301/400, Loss: 1.486, Accuracy: 97.500\n",
      "Epoch 302/400, Loss: 1.487, Accuracy: 97.450\n",
      "Epoch 303/400, Loss: 1.487, Accuracy: 97.400\n",
      "Epoch 304/400, Loss: 1.484, Accuracy: 97.750\n",
      "Epoch 305/400, Loss: 1.485, Accuracy: 97.650\n",
      "Epoch 306/400, Loss: 1.486, Accuracy: 97.550\n",
      "Epoch 307/400, Loss: 1.489, Accuracy: 97.250\n",
      "Epoch 308/400, Loss: 1.481, Accuracy: 98.000\n",
      "Epoch 309/400, Loss: 1.486, Accuracy: 97.550\n",
      "Epoch 310/400, Loss: 1.490, Accuracy: 97.150\n",
      "Epoch 311/400, Loss: 1.483, Accuracy: 97.800\n",
      "Epoch 312/400, Loss: 1.490, Accuracy: 97.150\n",
      "Epoch 313/400, Loss: 1.495, Accuracy: 96.600\n",
      "Epoch 314/400, Loss: 1.486, Accuracy: 97.550\n",
      "Epoch 315/400, Loss: 1.489, Accuracy: 97.200\n",
      "Epoch 316/400, Loss: 1.485, Accuracy: 97.650\n",
      "Epoch 317/400, Loss: 1.488, Accuracy: 97.350\n",
      "Epoch 318/400, Loss: 1.493, Accuracy: 96.800\n",
      "Epoch 319/400, Loss: 1.494, Accuracy: 96.700\n",
      "Epoch 320/400, Loss: 1.489, Accuracy: 97.300\n",
      "Epoch 321/400, Loss: 1.488, Accuracy: 97.300\n",
      "Epoch 322/400, Loss: 1.490, Accuracy: 97.150\n",
      "Epoch 323/400, Loss: 1.494, Accuracy: 96.750\n",
      "Epoch 324/400, Loss: 1.485, Accuracy: 97.550\n",
      "Epoch 325/400, Loss: 1.485, Accuracy: 97.600\n",
      "Epoch 326/400, Loss: 1.475, Accuracy: 98.600\n",
      "Epoch 327/400, Loss: 1.486, Accuracy: 97.550\n",
      "Epoch 328/400, Loss: 1.476, Accuracy: 98.500\n",
      "Epoch 329/400, Loss: 1.469, Accuracy: 99.200\n",
      "Epoch 330/400, Loss: 1.462, Accuracy: 99.900\n",
      "Epoch 331/400, Loss: 1.462, Accuracy: 99.900\n",
      "Epoch 332/400, Loss: 1.471, Accuracy: 99.050\n",
      "Epoch 333/400, Loss: 1.471, Accuracy: 99.000\n",
      "Epoch 334/400, Loss: 1.472, Accuracy: 98.950\n",
      "Epoch 335/400, Loss: 1.469, Accuracy: 99.200\n",
      "Epoch 336/400, Loss: 1.462, Accuracy: 99.900\n",
      "Epoch 337/400, Loss: 1.476, Accuracy: 98.500\n",
      "Epoch 338/400, Loss: 1.461, Accuracy: 100.000\n",
      "Epoch 339/400, Loss: 1.472, Accuracy: 98.900\n",
      "Epoch 340/400, Loss: 1.471, Accuracy: 99.050\n",
      "Epoch 341/400, Loss: 1.465, Accuracy: 99.600\n",
      "Epoch 342/400, Loss: 1.473, Accuracy: 98.800\n",
      "Epoch 343/400, Loss: 1.461, Accuracy: 100.000\n",
      "Epoch 344/400, Loss: 1.465, Accuracy: 99.550\n",
      "Epoch 345/400, Loss: 1.461, Accuracy: 100.000\n",
      "Epoch 346/400, Loss: 1.461, Accuracy: 100.000\n",
      "Epoch 347/400, Loss: 1.476, Accuracy: 98.500\n",
      "Epoch 348/400, Loss: 1.461, Accuracy: 100.000\n",
      "Epoch 349/400, Loss: 1.462, Accuracy: 99.900\n",
      "Epoch 350/400, Loss: 1.462, Accuracy: 99.900\n",
      "Epoch 351/400, Loss: 1.461, Accuracy: 100.000\n",
      "Epoch 352/400, Loss: 1.461, Accuracy: 100.000\n",
      "Epoch 353/400, Loss: 1.461, Accuracy: 100.000\n",
      "Epoch 354/400, Loss: 1.461, Accuracy: 100.000\n",
      "Epoch 355/400, Loss: 1.461, Accuracy: 100.000\n",
      "Epoch 356/400, Loss: 1.461, Accuracy: 100.000\n",
      "Epoch 357/400, Loss: 1.461, Accuracy: 100.000\n",
      "Epoch 358/400, Loss: 1.464, Accuracy: 99.750\n",
      "Epoch 359/400, Loss: 1.461, Accuracy: 100.000\n",
      "Epoch 360/400, Loss: 1.461, Accuracy: 100.000\n",
      "Epoch 361/400, Loss: 1.461, Accuracy: 100.000\n",
      "Epoch 362/400, Loss: 1.474, Accuracy: 98.750\n",
      "Epoch 363/400, Loss: 1.461, Accuracy: 100.000\n",
      "Epoch 364/400, Loss: 1.462, Accuracy: 99.950\n",
      "Epoch 365/400, Loss: 1.461, Accuracy: 100.000\n",
      "Epoch 366/400, Loss: 1.462, Accuracy: 99.950\n",
      "Epoch 367/400, Loss: 1.461, Accuracy: 100.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 368/400, Loss: 1.487, Accuracy: 97.450\n",
      "Epoch 369/400, Loss: 1.475, Accuracy: 98.550\n",
      "Epoch 370/400, Loss: 1.463, Accuracy: 99.800\n",
      "Epoch 371/400, Loss: 1.461, Accuracy: 100.000\n",
      "Epoch 372/400, Loss: 1.466, Accuracy: 99.550\n",
      "Epoch 373/400, Loss: 1.462, Accuracy: 99.950\n",
      "Epoch 374/400, Loss: 1.461, Accuracy: 100.000\n",
      "Epoch 375/400, Loss: 1.461, Accuracy: 100.000\n",
      "Epoch 376/400, Loss: 1.462, Accuracy: 99.950\n",
      "Epoch 377/400, Loss: 1.480, Accuracy: 98.150\n",
      "Epoch 378/400, Loss: 1.461, Accuracy: 100.000\n",
      "Epoch 379/400, Loss: 1.461, Accuracy: 100.000\n",
      "Epoch 380/400, Loss: 1.462, Accuracy: 99.950\n",
      "Epoch 381/400, Loss: 1.461, Accuracy: 100.000\n",
      "Epoch 382/400, Loss: 1.462, Accuracy: 99.950\n",
      "Epoch 383/400, Loss: 1.462, Accuracy: 99.950\n",
      "Epoch 384/400, Loss: 1.461, Accuracy: 100.000\n",
      "Epoch 385/400, Loss: 1.473, Accuracy: 98.800\n",
      "Epoch 386/400, Loss: 1.462, Accuracy: 99.900\n",
      "Epoch 387/400, Loss: 1.468, Accuracy: 99.350\n",
      "Epoch 388/400, Loss: 1.462, Accuracy: 99.950\n",
      "Epoch 389/400, Loss: 1.463, Accuracy: 99.800\n",
      "Epoch 390/400, Loss: 1.462, Accuracy: 99.950\n",
      "Epoch 391/400, Loss: 1.461, Accuracy: 100.000\n",
      "Epoch 392/400, Loss: 1.462, Accuracy: 99.900\n",
      "Epoch 393/400, Loss: 1.461, Accuracy: 100.000\n",
      "Epoch 394/400, Loss: 1.462, Accuracy: 99.900\n",
      "Epoch 395/400, Loss: 1.477, Accuracy: 98.450\n",
      "Epoch 396/400, Loss: 1.462, Accuracy: 99.900\n",
      "Epoch 397/400, Loss: 1.461, Accuracy: 100.000\n",
      "Epoch 398/400, Loss: 1.461, Accuracy: 100.000\n",
      "Epoch 399/400, Loss: 1.461, Accuracy: 100.000\n",
      "Epoch 400/400, Loss: 1.461, Accuracy: 100.000\n",
      "Test Accuracy: 99.99444484710693\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00      2941\n",
      "           2       1.00      1.00      1.00      1528\n",
      "           3       1.00      1.00      1.00      1507\n",
      "           4       1.00      1.00      1.00      3054\n",
      "           5       1.00      1.00      1.00      1500\n",
      "           6       1.00      1.00      1.00      1480\n",
      "           7       1.00      1.00      1.00      1508\n",
      "           8       1.00      1.00      1.00      1484\n",
      "           9       1.00      1.00      1.00      1510\n",
      "          10       1.00      1.00      1.00      1488\n",
      "\n",
      "    accuracy                           1.00     18000\n",
      "   macro avg       1.00      1.00      1.00     18000\n",
      "weighted avg       1.00      1.00      1.00     18000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 400\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.009) #0.009\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.8)\n",
    "\n",
    "for epo in range(num_epochs):\n",
    "    \n",
    "    loss,acc=epoch(train_loader,model,loss_function)\n",
    "    \n",
    "    print(\"Epoch {}/{}, Loss: {:.3f}, Accuracy: {:.3f}\".format(epo+1,num_epochs, loss.item(), acc))\n",
    "    \n",
    "\n",
    "X , y = next(iter(test_loader))\n",
    "\n",
    "preds=torch.softmax(model(X),axis=1)\n",
    "y_labels=torch.argmax(y,axis=1)\n",
    "pred_labels=torch.argmax(preds,axis=1)\n",
    "testacc=100 * torch.mean((pred_labels == y_labels).float()).item()\n",
    "print('Test Accuracy:', testacc)\n",
    "print(metrics.classification_report(y_labels+1, pred_labels+1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "49e002de",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected 3-dimensional input for 3-dimensional weight [32, 14, 3], but got 2-dimensional input of size [2000, 14] instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-6ac86e946405>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m             \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m             \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogits\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-28-1a52af2dff6e>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    261\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 263\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    257\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[1;32m--> 259\u001b[1;33m         return F.conv1d(input, weight, bias, self.stride,\n\u001b[0m\u001b[0;32m    260\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[0;32m    261\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected 3-dimensional input for 3-dimensional weight [32, 14, 3], but got 2-dimensional input of size [2000, 14] instead"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define your model as usual\n",
    "\n",
    "\n",
    "# Initialize the model and set it to evaluation mode\n",
    "# model = MulticlassClassification(num_feature = in_f, num_class=out_f)\n",
    "model.eval()\n",
    "\n",
    "# Define a temperature value to use during distillation\n",
    "T = 4\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.KLDivLoss(reduction='batchmean')\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.006) #0.009\n",
    "\n",
    "\n",
    "\n",
    "for epo in range(100):\n",
    "    for X, y in train_loader:\n",
    "    \n",
    "\n",
    "            logits = model(X)\n",
    "            logits = logits / T\n",
    "\n",
    "            # Calculate the loss\n",
    "            loss = criterion(torch.log_softmax(logits, dim=1), torch.softmax(y / T, dim=1))\n",
    "\n",
    "            # Use backpropagation to update the model's parameters\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    print(\"Epoch {}/{}, Loss: {:.3f}\".format(epo+1,num_epochs, loss.item()))\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "# Get the logits from the model\n",
    "\n",
    "# Scale the logits using the temperature\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0612fffc",
   "metadata": {},
   "source": [
    "## Advarsial Attack\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84da52bc",
   "metadata": {},
   "source": [
    "### FGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1c29e46f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected 3-dimensional input for 3-dimensional weight [32, 14, 3], but got 2-dimensional input of size [18000, 14] instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-ee7dcf569164>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0madversarial_examples\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mfgsm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mpreds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madversarial_examples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-49-ee7dcf569164>\u001b[0m in \u001b[0;36mfgsm\u001b[1;34m(model, X, y, **kwargs)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mfgsm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorchattacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFGSM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0madversarial_examples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfgsm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0madversarial_examples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchattacks\\attack.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, labels, *args, **kwargs)\u001b[0m\n\u001b[0;32m    427\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_normalization_applied\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 429\u001b[1;33m             \u001b[0madv_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    430\u001b[0m             \u001b[0madv_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madv_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturn_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchattacks\\attacks\\fgsm.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, images, labels)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_logits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;31m# Calculate loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchattacks\\attack.py\u001b[0m in \u001b[0;36mget_logits\u001b[1;34m(self, inputs, labels, *args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_normalization_applied\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m             \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlogits\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-28-1a52af2dff6e>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    261\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 263\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    257\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[1;32m--> 259\u001b[1;33m         return F.conv1d(input, weight, bias, self.stride,\n\u001b[0m\u001b[0;32m    260\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[0;32m    261\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected 3-dimensional input for 3-dimensional weight [32, 14, 3], but got 2-dimensional input of size [18000, 14] instead"
     ]
    }
   ],
   "source": [
    "# 1- FGSM \n",
    "  \n",
    "def fgsm(model,X,y, **kwargs):\n",
    "    \n",
    "    fgsm = torchattacks.FGSM(model,**kwargs)\n",
    "    adversarial_examples = fgsm(X, torch.argmax(y,axis=1))\n",
    "    \n",
    "    return adversarial_examples\n",
    "\n",
    "    \n",
    "\n",
    "for i in np.arange(0,0.1,0.01):\n",
    "    X , y = next(iter(test_loader))\n",
    "\n",
    "\n",
    "    adversarial_examples= fgsm(model,X,y, eps=i)\n",
    "\n",
    "    preds=torch.softmax(model(adversarial_examples),axis=1)\n",
    "\n",
    "    y_labels=torch.argmax(y,axis=1)\n",
    "    pred_labels=torch.argmax(preds,axis=1)\n",
    "\n",
    "    testacc=100 * torch.mean((pred_labels == y_labels).float()).item()\n",
    "    print('epsilon:', i ,' Test Accuracy:', testacc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35344b5a",
   "metadata": {},
   "source": [
    "### PGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "06a1b511",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected 3-dimensional input for 3-dimensional weight [32, 14, 3], but got 2-dimensional input of size [18000, 14] instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-997911711685>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0madversarial_examples\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mpgd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.005\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mpreds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madversarial_examples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-53-997911711685>\u001b[0m in \u001b[0;36mpgd\u001b[1;34m(model, X, y, **kwargs)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mpgd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorchattacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0madversarial_examples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpgd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0madversarial_examples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchattacks\\attack.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, labels, *args, **kwargs)\u001b[0m\n\u001b[0;32m    427\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_normalization_applied\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 429\u001b[1;33m             \u001b[0madv_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    430\u001b[0m             \u001b[0madv_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madv_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturn_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchattacks\\attacks\\pgd.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, images, labels)\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[0madv_images\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_logits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madv_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[1;31m# Calculate loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchattacks\\attack.py\u001b[0m in \u001b[0;36mget_logits\u001b[1;34m(self, inputs, labels, *args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_normalization_applied\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m             \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlogits\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-28-1a52af2dff6e>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    261\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 263\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    257\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[1;32m--> 259\u001b[1;33m         return F.conv1d(input, weight, bias, self.stride,\n\u001b[0m\u001b[0;32m    260\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[0;32m    261\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected 3-dimensional input for 3-dimensional weight [32, 14, 3], but got 2-dimensional input of size [18000, 14] instead"
     ]
    }
   ],
   "source": [
    "# 2- PGD \n",
    "\n",
    "def pgd(model,X,y, **kwargs):\n",
    "    \n",
    "    pgd = torchattacks.PGD(model,**kwargs)\n",
    "    adversarial_examples = pgd(X, torch.argmax(y,axis=1))\n",
    "    \n",
    "    return adversarial_examples\n",
    "\n",
    "    \n",
    "\n",
    "for i in np.arange(0,0.1,0.01):\n",
    "    X , y = next(iter(test_loader))\n",
    "\n",
    "\n",
    "    adversarial_examples= pgd(model,X,y, eps=i, alpha=0.005, steps=10, random_start=False)\n",
    "\n",
    "    preds=torch.softmax(model(adversarial_examples),axis=1)\n",
    "\n",
    "    y_labels=torch.argmax(y,axis=1)\n",
    "    pred_labels=torch.argmax(preds,axis=1)\n",
    "\n",
    "    testacc=100 * torch.mean((pred_labels == y_labels).float()).item()\n",
    "    print('epsilon:', i ,' Test Accuracy:', testacc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3682f28",
   "metadata": {},
   "source": [
    "### Carlini and Wagner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ef7787d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c: 1  Test Accuracy: 98.70256185531616\n",
      "c: 0  Test Accuracy: 98.72820377349854\n"
     ]
    }
   ],
   "source": [
    "# 3- C&W\n",
    "\n",
    "def cw(model, X,y,**kwargs):\n",
    "    \n",
    "    cw = torchattacks.CW(model,**kwargs)\n",
    "    adversarial_examples = cw(X, torch.argmax(y,axis=1))\n",
    "    \n",
    "    return adversarial_examples\n",
    "\n",
    "X , y = next(iter(test_loader))\n",
    "\n",
    "adversarial_examples= cw(model,X,y, c=1, kappa=0, steps=100, lr=0.01) \n",
    "\n",
    "preds=torch.softmax(model(adversarial_examples),axis=1)\n",
    "\n",
    "y_labels=torch.argmax(y,axis=1)\n",
    "pred_labels=torch.argmax(preds,axis=1)\n",
    "\n",
    "testacc=100 * torch.mean((pred_labels == y_labels).float()).item()\n",
    "print('c:', 1 ,' Test Accuracy:', testacc)\n",
    "    \n",
    "X , y = next(iter(test_loader))\n",
    "\n",
    "\n",
    "preds=torch.softmax(model(X),axis=1)\n",
    "\n",
    "y_labels=torch.argmax(y,axis=1)\n",
    "pred_labels=torch.argmax(preds,axis=1)\n",
    "\n",
    "testacc=100 * torch.mean((pred_labels == y_labels).float()).item()\n",
    "print('c:', 0 ,' Test Accuracy:', testacc)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5e10b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876a2c54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7583a5bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cad4434c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_robust_PGD = MulticlassClassification(num_feature = in_f, num_class=out_f)\n",
    "model_robust_FGSM = MulticlassClassification(num_feature = in_f, num_class=out_f)\n",
    "model_robust_CW = MulticlassClassification(num_feature = in_f, num_class=out_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90e921a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4d4f80fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_adv(loader, model,attack,**kwargs):\n",
    "    for X, y in loader:\n",
    "        \n",
    "        preds = model(X)\n",
    "\n",
    "        preds=torch.softmax(preds,axis=1)\n",
    "        \n",
    "        loss = loss_function(preds, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Adv\n",
    "        \n",
    "        adv = attack(model,X,y, **kwargs)\n",
    "\n",
    "\n",
    "        preds = model(adv)\n",
    "   \n",
    "\n",
    "        preds=torch.softmax(preds,axis=1)\n",
    "        \n",
    "        loss = loss_function(preds, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        y_labels=torch.argmax(y,axis=1)\n",
    "        pred_labels=torch.argmax(preds,axis=1)\n",
    "        \n",
    "        acc=100 * torch.mean((pred_labels == y_labels).float()).item()\n",
    "        \n",
    "    return loss,acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345da70f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33d97b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6e8c35c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pgd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-aaa67dd1a0cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepoch_adv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel_robust_PGD\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpgd\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Epoch {}/{}, Loss: {:.3f}, Accuracy: {:.3f}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepo\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pgd' is not defined"
     ]
    }
   ],
   "source": [
    "#PGD Training\n",
    "\n",
    "num_epochs = 500\n",
    "epsilon=0.05\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model_robust_PGD.parameters(), lr=0.006) #0.009\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "for epo in range(num_epochs):\n",
    "\n",
    "\n",
    "    loss,acc=epoch_adv(train_loader,model_robust_PGD,pgd,eps=epsilon, alpha=0.01, steps=10, random_start=False)\n",
    "\n",
    "    print(\"Epoch {}/{}, Loss: {:.3f}, Accuracy: {:.3f}\".format(epo+1,num_epochs, loss.item(), acc))\n",
    "\n",
    "\n",
    "\n",
    "    X , y = next(iter(test_loader))\n",
    "\n",
    "    adversarial_examples = pgd(model_robust_PGD,X,y, eps=epsilon, alpha=0.01, steps=10, random_start=False)\n",
    "\n",
    "    preds=torch.softmax(model_robust_PGD(adversarial_examples),axis=1)\n",
    "\n",
    "    y_labels=torch.argmax(y,axis=1)\n",
    "    pred_labels=torch.argmax(preds,axis=1)\n",
    "\n",
    "    testacc=100 * torch.mean((pred_labels == y_labels).float()).item()\n",
    "    print('epsilon:',epsilon,' Test Accuracy:', testacc)\n",
    "    \n",
    "    if epo==num_epochs-1:\n",
    "        \n",
    "        print(metrics.classification_report(y_labels+1, pred_labels+1))\n",
    "    \n",
    "    \n",
    "    X , y = next(iter(test_loader))\n",
    "\n",
    "\n",
    "    preds=torch.softmax(model_robust_PGD(X),axis=1)\n",
    "\n",
    "    y_labels=torch.argmax(y,axis=1)\n",
    "    pred_labels=torch.argmax(preds,axis=1)\n",
    "\n",
    "    testacc=100 * torch.mean((pred_labels == y_labels).float()).item()\n",
    "    print('epsilon:',0,' Test Accuracy:', testacc)\n",
    "    \n",
    "    if epo==num_epochs-1:\n",
    "        \n",
    "        print(metrics.classification_report(y_labels+1, pred_labels+1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b5d908",
   "metadata": {},
   "outputs": [],
   "source": [
    " X , y = next(iter(test_loader))\n",
    "\n",
    "adversarial_examples = pgd(model_robust_PGD,X,y, eps=epsilon, alpha=0.01, steps=10, random_start=False)\n",
    "\n",
    "preds=torch.softmax(model_robust_PGD(adversarial_examples),axis=1)\n",
    "\n",
    "y_labels=torch.argmax(y,axis=1)\n",
    "pred_labels=torch.argmax(preds,axis=1)\n",
    "\n",
    "testacc=100 * torch.mean((pred_labels == y_labels).float()).item()\n",
    "print('epsilon:',epsilon,' Test Accuracy:', testacc)\n",
    "\n",
    "\n",
    "print(metrics.classification_report(y_labels+1, pred_labels+1))\n",
    "    \n",
    "    \n",
    "X , y = next(iter(test_loader))\n",
    "\n",
    "\n",
    "preds=torch.softmax(model_robust_PGD(X),axis=1)\n",
    "\n",
    "y_labels=torch.argmax(y,axis=1)\n",
    "pred_labels=torch.argmax(preds,axis=1)\n",
    "\n",
    "testacc=100 * torch.mean((pred_labels == y_labels).float()).item()\n",
    "print('epsilon:',0,' Test Accuracy:', testacc)\n",
    "\n",
    "print(metrics.classification_report(y_labels+1, pred_labels+1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bf5911",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FGSM Training\n",
    "\n",
    "num_epochs = 500\n",
    "epsilon=0.05\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model_robust_FGSM.parameters(), lr=0.009) #0.009\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "for epo in range(num_epochs):\n",
    "\n",
    "\n",
    "    loss,acc=epoch_adv(train_loader,model_robust_FGSM,fgsm,eps=epsilon)\n",
    "\n",
    "    print(\"Epoch {}/{}, Loss: {:.3f}, Accuracy: {:.3f}\".format(epo+1,num_epochs, loss.item(), acc))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    X , y = next(iter(test_loader))\n",
    "\n",
    "    adversarial_examples = fgsm(model_robust_FGSM,X,y, eps=epsilon)\n",
    "\n",
    "    preds=torch.softmax(model_robust_FGSM(adversarial_examples),axis=1)\n",
    "\n",
    "    y_labels=torch.argmax(y,axis=1)\n",
    "    pred_labels=torch.argmax(preds,axis=1)\n",
    "\n",
    "    testacc=100 * torch.mean((pred_labels == y_labels).float()).item()\n",
    "    print('epsilon:',epsilon,' Test Accuracy:', testacc)\n",
    "    \n",
    "        \n",
    "    if epo==num_epochs-1:\n",
    "        \n",
    "        print(metrics.classification_report(y_labels+1, pred_labels+1))\n",
    "    \n",
    "    \n",
    "    X , y = next(iter(test_loader))\n",
    "\n",
    "\n",
    "    preds=torch.softmax(model_robust_FGSM(X),axis=1)\n",
    "\n",
    "    y_labels=torch.argmax(y,axis=1)\n",
    "    pred_labels=torch.argmax(preds,axis=1)\n",
    "\n",
    "    testacc=100 * torch.mean((pred_labels == y_labels).float()).item()\n",
    "    print('epsilon:',0,' Test Accuracy:', testacc)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    if epo==num_epochs-1:\n",
    "        \n",
    "        print(metrics.classification_report(y_labels+1, pred_labels+1))\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c857fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9964bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CW Training\n",
    "\n",
    "num_epochs = 500\n",
    "c=1\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model_robust_CW.parameters(), lr=0.006) #0.009\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "for epo in range(num_epochs):\n",
    "\n",
    "\n",
    "    loss,acc=epoch_adv(train_loader,model_robust_CW,cw,c=c, kappa=0, steps=50, lr=0.01) \n",
    "\n",
    "    print(\"Epoch {}/{}, Loss: {:.3f}, Accuracy: {:.3f}\".format(epo+1,num_epochs, loss.item(), acc))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c61666d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X , y = next(iter(test_loader))\n",
    "\n",
    "adversarial_examples = cw(model_robust_CW,X,y,c=1, kappa=0, steps=50, lr=0.01) \n",
    "\n",
    "preds=torch.softmax(model_robust_CW(adversarial_examples),axis=1)\n",
    "\n",
    "y_labels=torch.argmax(y,axis=1)\n",
    "pred_labels=torch.argmax(preds,axis=1)\n",
    "\n",
    "testacc=100 * torch.mean((pred_labels == y_labels).float()).item()\n",
    "print('c:',c,' Test Accuracy:', testacc)\n",
    "\n",
    "\n",
    "\n",
    "print(metrics.classification_report(y_labels+1, pred_labels+1))\n",
    "\n",
    "\n",
    "X , y = next(iter(test_loader))\n",
    "\n",
    "\n",
    "preds=torch.softmax(model_robust_CW(X),axis=1)\n",
    "\n",
    "y_labels=torch.argmax(y,axis=1)\n",
    "pred_labels=torch.argmax(preds,axis=1)\n",
    "\n",
    "testacc=100 * torch.mean((pred_labels == y_labels).float()).item()\n",
    "print('c',c,' Test Accuracy:', testacc)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(metrics.classification_report(y_labels+1, pred_labels+1))\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed28f9e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c61efa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X , y = next(iter(test_loader))\n",
    "\n",
    "adversarial_examples = cw(model,X,y,c=1, kappa=0, steps=50, lr=0.01) \n",
    "\n",
    "preds=torch.softmax(model(adversarial_examples),axis=1)\n",
    "\n",
    "y_labels=torch.argmax(y,axis=1)\n",
    "pred_labels=torch.argmax(preds,axis=1)\n",
    "\n",
    "testacc=100 * torch.mean((pred_labels == y_labels).float()).item()\n",
    "print('c:',1,' Test Accuracy:', testacc)\n",
    "\n",
    "\n",
    "\n",
    "print(metrics.classification_report(y_labels+1, pred_labels+1))\n",
    "\n",
    "\n",
    "X , y = next(iter(test_loader))\n",
    "\n",
    "\n",
    "preds=torch.softmax(model(X),axis=1)\n",
    "\n",
    "y_labels=torch.argmax(y,axis=1)\n",
    "pred_labels=torch.argmax(preds,axis=1)\n",
    "\n",
    "testacc=100 * torch.mean((pred_labels == y_labels).float()).item()\n",
    "print('c',1,' Test Accuracy:', testacc)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(metrics.classification_report(y_labels+1, pred_labels+1))\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e43579e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sgenv",
   "language": "python",
   "name": "sgenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
