{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ce03286",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "import os\n",
    "import torch \n",
    "from decimal import Decimal\n",
    "from torch.utils.data import Dataset, DataLoader,TensorDataset\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing\n",
    "import glob\n",
    "import os\n",
    "import torchattacks\n",
    "\n",
    "from scipy import linalg\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from torch.autograd import Variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c553ce85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv('data_without_ioa.csv')\n",
    "df2=pd.read_csv('data_with_ioa.csv')\n",
    "# df3=pd.read_csv('calss3_generated.csv')\n",
    "# df4=pd.read_csv('calss4_generated.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b88fefe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "714fbf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.drop(columns=df1.columns[0], axis=1, inplace=True)\n",
    "df2.drop(columns=df2.columns[0], axis=1, inplace=True)\n",
    "# df3.drop(columns=df3.columns[0], axis=1, inplace=True)\n",
    "# df4.drop(columns=df4.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df2.drop(['ioa'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df=pd.concat([df1,df2])\n",
    "for i in ['oa']: #'fmt','numix',\n",
    "    df.drop([i], axis=1, inplace=True)\n",
    "\n",
    "# df=pd.concat([df_int])\n",
    "    \n",
    "# df.drop(['dstIP','srcIP','oa'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "912b39a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['label']!=0]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfad741f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3939353\n",
       "1     121777\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1ae30e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#majority under sampling\n",
    "# df\n",
    "# data=df[df['label']!=0]\n",
    "# data_s = resample(df[df['label']==0], replace=False,n_samples=10000,random_state=123)\n",
    "# df=pd.concat([data,data_s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bf729bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#All sampling\n",
    "data_train_sampled=pd.DataFrame([],columns=df.columns.values,dtype=float)\n",
    "sampling=200000\n",
    "for i in df['label'].unique():\n",
    "\n",
    "    \n",
    "    if df[df['label']==i].shape[0]>sampling:\n",
    "        \n",
    "        data_s = resample(df[df['label']==i], replace=False,n_samples=sampling,random_state=123)\n",
    "        data_train_sampled=pd.concat([data_train_sampled,data_s])\n",
    "    \n",
    "    else:\n",
    "        data_s = resample(df[df['label']==i], replace=True,n_samples=sampling,random_state=123) \n",
    "        data_train_sampled=pd.concat([data_train_sampled,data_s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f91d2637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X,y = df.iloc[:, :-1], df.iloc[:, [-1]]\n",
    "X, y = data_train_sampled.iloc[:, :-1], data_train_sampled.iloc[:, [-1]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afdfd5bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TimeStamp</th>\n",
       "      <th>Relative Time</th>\n",
       "      <th>srcIP</th>\n",
       "      <th>dstIP</th>\n",
       "      <th>srcPort</th>\n",
       "      <th>dstPort</th>\n",
       "      <th>ipLen</th>\n",
       "      <th>len</th>\n",
       "      <th>fmt</th>\n",
       "      <th>uType</th>\n",
       "      <th>asduType</th>\n",
       "      <th>numix</th>\n",
       "      <th>cot</th>\n",
       "      <th>addr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1374229</th>\n",
       "      <td>7.351659</td>\n",
       "      <td>314462.454837</td>\n",
       "      <td>1.677725e+08</td>\n",
       "      <td>1.677724e+08</td>\n",
       "      <td>49716.0</td>\n",
       "      <td>2404.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>15.281557</td>\n",
       "      <td>2798.572989</td>\n",
       "      <td>3.232238e+09</td>\n",
       "      <td>3.232239e+09</td>\n",
       "      <td>61254.0</td>\n",
       "      <td>2404.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818189</th>\n",
       "      <td>19.494926</td>\n",
       "      <td>206436.879187</td>\n",
       "      <td>3.232236e+09</td>\n",
       "      <td>3.232236e+09</td>\n",
       "      <td>2404.0</td>\n",
       "      <td>42126.0</td>\n",
       "      <td>760.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749925</th>\n",
       "      <td>15.211046</td>\n",
       "      <td>428816.325839</td>\n",
       "      <td>1.677724e+08</td>\n",
       "      <td>1.677725e+08</td>\n",
       "      <td>2404.0</td>\n",
       "      <td>49716.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982782</th>\n",
       "      <td>3.202968</td>\n",
       "      <td>212775.545622</td>\n",
       "      <td>1.677724e+08</td>\n",
       "      <td>1.677725e+08</td>\n",
       "      <td>2404.0</td>\n",
       "      <td>49716.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535871</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1669967</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169102</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1656035</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468194</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         TimeStamp  Relative Time         srcIP         dstIP  srcPort  \\\n",
       "1374229   7.351659  314462.454837  1.677725e+08  1.677724e+08  49716.0   \n",
       "801      15.281557    2798.572989  3.232238e+09  3.232239e+09  61254.0   \n",
       "818189   19.494926  206436.879187  3.232236e+09  3.232236e+09   2404.0   \n",
       "1749925  15.211046  428816.325839  1.677724e+08  1.677725e+08   2404.0   \n",
       "982782    3.202968  212775.545622  1.677724e+08  1.677725e+08   2404.0   \n",
       "...            ...            ...           ...           ...      ...   \n",
       "535871    1.000000       1.000000  1.000000e+00  1.000000e+00      1.0   \n",
       "1669967   1.000000       1.000000  1.000000e+00  1.000000e+00      1.0   \n",
       "169102    1.000000       1.000000  1.000000e+00  1.000000e+00      1.0   \n",
       "1656035   1.000000       1.000000  1.000000e+00  1.000000e+00      1.0   \n",
       "1468194   1.000000       1.000000  1.000000e+00  1.000000e+00      1.0   \n",
       "\n",
       "         dstPort  ipLen   len  fmt  uType  asduType  numix   cot  addr  \n",
       "1374229   2404.0   46.0   4.0  2.0    2.0       9.0    1.0   3.0  55.0  \n",
       "801       2404.0   46.0   4.0  2.0    2.0       9.0    1.0   3.0  55.0  \n",
       "818189   42126.0  760.0  54.0  0.0    1.0      30.0    4.0  20.0  10.0  \n",
       "1749925  49716.0   58.0  16.0  1.0    2.0       9.0    1.0   3.0  55.0  \n",
       "982782   49716.0   58.0  16.0  1.0    2.0       9.0    1.0   3.0  55.0  \n",
       "...          ...    ...   ...  ...    ...       ...    ...   ...   ...  \n",
       "535871       1.0    1.0   1.0  1.0    1.0       1.0    1.0   1.0   1.0  \n",
       "1669967      1.0    1.0   1.0  1.0    1.0       1.0    1.0   1.0   1.0  \n",
       "169102       1.0    1.0   1.0  1.0    1.0       1.0    1.0   1.0   1.0  \n",
       "1656035      1.0    1.0   1.0  1.0    1.0       1.0    1.0   1.0   1.0  \n",
       "1468194      1.0    1.0   1.0  1.0    1.0       1.0    1.0   1.0   1.0  \n",
       "\n",
       "[400000 rows x 14 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57e22054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    200000\n",
       "1.0    200000\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y['label'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22b855e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-224295ef9961>:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfc.fit(X, y);\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier();\n",
    "\n",
    "# fit random forest classifier on the training set\n",
    "rfc.fit(X, y);\n",
    "# extract important features\n",
    "score = np.round(rfc.feature_importances_,3)\n",
    "importances = pd.DataFrame({'feature':X.columns,'importance':score})\n",
    "importances = importances.sort_values('importance',ascending=False).set_index('feature')\n",
    "# plot importances\n",
    "plt.rcParams['figure.figsize'] = (11, 4)\n",
    "importances.plot.bar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7fd2f7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'asduType','len'\n",
    "# for i in ['fmt','numix','oa']:\n",
    "#     X.drop([i], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a23d84f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TimeStamp', 'Relative Time', 'srcIP', 'dstIP', 'srcPort', 'dstPort',\n",
       "       'ipLen', 'len', 'fmt', 'uType', 'asduType', 'numix', 'cot', 'addr'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b9a4789",
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = MinMaxScaler()\n",
    "\n",
    "X_mm = mm.fit_transform(X) \n",
    "\n",
    "\n",
    "df_data=torch.Tensor(X_mm)\n",
    "df_label=y.values[:,0]\n",
    "\n",
    "# y=torch.Tensor(y.values)\n",
    "\n",
    "\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = df_label.reshape(len(df_label), 1)\n",
    "encoded_label = onehot_encoder.fit_transform(integer_encoded)\n",
    "encoded_label=torch.Tensor(encoded_label)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4802446e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_scaled=pd.DataFrame(X_mm,columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71d48691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd528bbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TimeStamp</th>\n",
       "      <th>Relative Time</th>\n",
       "      <th>srcIP</th>\n",
       "      <th>dstIP</th>\n",
       "      <th>srcPort</th>\n",
       "      <th>dstPort</th>\n",
       "      <th>ipLen</th>\n",
       "      <th>len</th>\n",
       "      <th>fmt</th>\n",
       "      <th>uType</th>\n",
       "      <th>asduType</th>\n",
       "      <th>numix</th>\n",
       "      <th>cot</th>\n",
       "      <th>addr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.311563</td>\n",
       "      <td>0.537529</td>\n",
       "      <td>0.051906</td>\n",
       "      <td>0.051906</td>\n",
       "      <td>0.811634</td>\n",
       "      <td>0.039231</td>\n",
       "      <td>0.058065</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.000839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.647634</td>\n",
       "      <td>0.004784</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.039231</td>\n",
       "      <td>0.058065</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.000839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.826197</td>\n",
       "      <td>0.352874</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.039231</td>\n",
       "      <td>0.687721</td>\n",
       "      <td>0.979355</td>\n",
       "      <td>0.210317</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.233871</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.644645</td>\n",
       "      <td>0.733000</td>\n",
       "      <td>0.051906</td>\n",
       "      <td>0.051906</td>\n",
       "      <td>0.039231</td>\n",
       "      <td>0.811634</td>\n",
       "      <td>0.073548</td>\n",
       "      <td>0.059524</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.000839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.135741</td>\n",
       "      <td>0.363709</td>\n",
       "      <td>0.051906</td>\n",
       "      <td>0.051906</td>\n",
       "      <td>0.039231</td>\n",
       "      <td>0.811634</td>\n",
       "      <td>0.073548</td>\n",
       "      <td>0.059524</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.000839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399995</th>\n",
       "      <td>0.042379</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399996</th>\n",
       "      <td>0.042379</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399997</th>\n",
       "      <td>0.042379</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399998</th>\n",
       "      <td>0.042379</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399999</th>\n",
       "      <td>0.042379</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        TimeStamp  Relative Time     srcIP     dstIP   srcPort   dstPort  \\\n",
       "0        0.311563       0.537529  0.051906  0.051906  0.811634  0.039231   \n",
       "1        0.647634       0.004784  1.000000  1.000000  1.000000  0.039231   \n",
       "2        0.826197       0.352874  0.999999  0.999999  0.039231  0.687721   \n",
       "3        0.644645       0.733000  0.051906  0.051906  0.039231  0.811634   \n",
       "4        0.135741       0.363709  0.051906  0.051906  0.039231  0.811634   \n",
       "...           ...            ...       ...       ...       ...       ...   \n",
       "399995   0.042379       0.000002  0.000000  0.000000  0.000000  0.000000   \n",
       "399996   0.042379       0.000002  0.000000  0.000000  0.000000  0.000000   \n",
       "399997   0.042379       0.000002  0.000000  0.000000  0.000000  0.000000   \n",
       "399998   0.042379       0.000002  0.000000  0.000000  0.000000  0.000000   \n",
       "399999   0.042379       0.000002  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "           ipLen       len  fmt     uType  asduType  numix       cot      addr  \n",
       "0       0.058065  0.011905  1.0  0.666667  0.064516    0.0  0.105263  0.000839  \n",
       "1       0.058065  0.011905  1.0  0.666667  0.064516    0.0  0.105263  0.000839  \n",
       "2       0.979355  0.210317  0.0  0.333333  0.233871    1.0  1.000000  0.000153  \n",
       "3       0.073548  0.059524  0.5  0.666667  0.064516    0.0  0.105263  0.000839  \n",
       "4       0.073548  0.059524  0.5  0.666667  0.064516    0.0  0.105263  0.000839  \n",
       "...          ...       ...  ...       ...       ...    ...       ...       ...  \n",
       "399995  0.000000  0.000000  0.5  0.333333  0.000000    0.0  0.000000  0.000015  \n",
       "399996  0.000000  0.000000  0.5  0.333333  0.000000    0.0  0.000000  0.000015  \n",
       "399997  0.000000  0.000000  0.5  0.333333  0.000000    0.0  0.000000  0.000015  \n",
       "399998  0.000000  0.000000  0.5  0.333333  0.000000    0.0  0.000000  0.000015  \n",
       "399999  0.000000  0.000000  0.5  0.333333  0.000000    0.0  0.000000  0.000015  \n",
       "\n",
       "[400000 rows x 14 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3bb2a24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_data, encoded_label, test_size=0.3,random_state=109) # 70% training and 30% test\n",
    "# X_train = X_train.unsqueeze(1)\n",
    "# X_test = X_test.unsqueeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e6bdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d727c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(X_train, y_train)\n",
    "test_data = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=1000)#train_data.tensors[0].shape[0])\n",
    "test_loader = DataLoader(test_data, batch_size=test_data.tensors[0].shape[0])\n",
    "\n",
    "# print(\"Training data batches:\")\n",
    "# for X, y in train_loader:\n",
    "#     print(X.shape, y.shape)\n",
    "    \n",
    "# print(\"\\nTest data batches:\")\n",
    "# for X, y in test_loader:\n",
    "#     print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a6dff87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "in_f=train_data.tensors[0].shape[1]\n",
    "out_f=train_data.tensors[1].shape[1]\n",
    "\n",
    "class BinaryClassification(nn.Module):\n",
    "    def __init__(self, num_feature, num_class):\n",
    "        super(BinaryClassification, self).__init__()\n",
    "        \n",
    "        self.layer_1 = nn.Linear(num_feature, 512)\n",
    "        self.layer_2 = nn.Linear(512, 128)\n",
    "        self.layer_3 = nn.Linear(128, 64)\n",
    "        self.layer_out = nn.Linear(64, num_class) \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(512)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(128)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(64)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer_1(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.layer_2(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.layer_3(x)\n",
    "        x = self.batchnorm3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.layer_out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "431b65cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = BinaryClassification(num_feature = in_f, num_class=out_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96ed8f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(14, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(128 * 4, 512)\n",
    "        self.fc2 = nn.Linear(512, 11)\n",
    "\n",
    "    def forward(self, x):\n",
    "            \n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 128 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0854dc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5b13e99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch(loader, model):\n",
    "    for X, y in loader:\n",
    "        #X=X.reshape(1, 1000, 14)\n",
    "\n",
    "        #X = X[:, :, :14]\n",
    "\n",
    "        preds = model(X)\n",
    "        preds=torch.softmax(preds,axis=1)\n",
    "        \n",
    "        loss = loss_function(preds, y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        y_labels=torch.argmax(y,axis=1)\n",
    "        pred_labels=torch.argmax(preds,axis=1)\n",
    "        \n",
    "        acc=100 * torch.mean((pred_labels == y_labels).float()).item()\n",
    "        #     print(metrics.classification_report(y_labels, pred_labels))\n",
    "\n",
    "        \n",
    "    return loss,acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6928847a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "1D target tensor expected, multi-target not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-e69924ba9a05>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Epoch {}/{}, Loss: {:.3f}, Accuracy: {:.3f}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepo\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-23-382a340e02c7>\u001b[0m in \u001b[0;36mepoch\u001b[1;34m(loader, model)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mpreds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1045\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1047\u001b[1;33m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[0;32m   1048\u001b[0m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0;32m   1049\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[0;32m   2691\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2692\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2693\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2694\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2695\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[0;32m   2386\u001b[0m         )\n\u001b[0;32m   2387\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2388\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2389\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2390\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: 1D target tensor expected, multi-target not supported"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.006) #0.009\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.8)\n",
    "\n",
    "for epo in range(num_epochs):\n",
    "    \n",
    "    loss,acc=epoch(train_loader,model)\n",
    "    \n",
    "    print(\"Epoch {}/{}, Loss: {:.3f}, Accuracy: {:.3f}\".format(epo+1,num_epochs, loss.item(), acc))\n",
    "    \n",
    "\n",
    "    X , y = next(iter(test_loader))\n",
    "\n",
    "    preds=torch.softmax(model(X),axis=1)\n",
    "    y_labels=torch.argmax(y,axis=1)\n",
    "    pred_labels=torch.argmax(preds,axis=1)\n",
    "    testacc=100 * torch.mean((pred_labels == y_labels).float()).item()\n",
    "    print('Test Accuracy:', testacc)\n",
    "    print(metrics.classification_report(y_labels+1, pred_labels+1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0612fffc",
   "metadata": {},
   "source": [
    "## Advarsial Attack\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84da52bc",
   "metadata": {},
   "source": [
    "### FGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c29e46f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsilon: 0.0  Test Accuracy: 100.0\n",
      "epsilon: 0.01  Test Accuracy: 100.0\n",
      "epsilon: 0.02  Test Accuracy: 100.0\n",
      "epsilon: 0.03  Test Accuracy: 100.0\n",
      "epsilon: 0.04  Test Accuracy: 100.0\n",
      "epsilon: 0.05  Test Accuracy: 100.0\n",
      "epsilon: 0.06  Test Accuracy: 100.0\n",
      "epsilon: 0.07  Test Accuracy: 100.0\n",
      "epsilon: 0.08  Test Accuracy: 100.0\n",
      "epsilon: 0.09  Test Accuracy: 100.0\n"
     ]
    }
   ],
   "source": [
    "# 1- FGSM \n",
    "  \n",
    "def fgsm(model,X,y, **kwargs):\n",
    "    \n",
    "    fgsm = torchattacks.FGSM(model,**kwargs)\n",
    "    adversarial_examples = fgsm(X, torch.argmax(y,axis=1))\n",
    "    \n",
    "    return adversarial_examples\n",
    "\n",
    "    \n",
    "\n",
    "for i in np.arange(0,0.1,0.01):\n",
    "    X , y = next(iter(test_loader))\n",
    "\n",
    "\n",
    "    adversarial_examples= fgsm(model,X,y, eps=i)\n",
    "\n",
    "    preds=torch.softmax(model(adversarial_examples),axis=1)\n",
    "\n",
    "    y_labels=torch.argmax(y,axis=1)\n",
    "    pred_labels=torch.argmax(preds,axis=1)\n",
    "\n",
    "    testacc=100 * torch.mean((pred_labels == y_labels).float()).item()\n",
    "    print('epsilon:', i ,' Test Accuracy:', testacc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35344b5a",
   "metadata": {},
   "source": [
    "### PGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "06a1b511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsilon: 0.0  Test Accuracy: 100.0\n",
      "epsilon: 0.01  Test Accuracy: 100.0\n",
      "epsilon: 0.02  Test Accuracy: 100.0\n",
      "epsilon: 0.03  Test Accuracy: 100.0\n",
      "epsilon: 0.04  Test Accuracy: 100.0\n",
      "epsilon: 0.05  Test Accuracy: 100.0\n",
      "epsilon: 0.06  Test Accuracy: 100.0\n",
      "epsilon: 0.07  Test Accuracy: 100.0\n",
      "epsilon: 0.08  Test Accuracy: 100.0\n",
      "epsilon: 0.09  Test Accuracy: 100.0\n"
     ]
    }
   ],
   "source": [
    "# 2- PGD \n",
    "\n",
    "def pgd(model,X,y, **kwargs):\n",
    "    \n",
    "    pgd = torchattacks.PGD(model,**kwargs)\n",
    "    adversarial_examples = pgd(X, torch.argmax(y,axis=1))\n",
    "    \n",
    "    return adversarial_examples\n",
    "\n",
    "    \n",
    "\n",
    "for i in np.arange(0,0.1,0.01):\n",
    "    X , y = next(iter(test_loader))\n",
    "\n",
    "\n",
    "    adversarial_examples= pgd(model,X,y, eps=i, alpha=0.005, steps=10, random_start=False)\n",
    "\n",
    "    preds=torch.softmax(model(adversarial_examples),axis=1)\n",
    "\n",
    "    y_labels=torch.argmax(y,axis=1)\n",
    "    pred_labels=torch.argmax(preds,axis=1)\n",
    "\n",
    "    testacc=100 * torch.mean((pred_labels == y_labels).float()).item()\n",
    "    print('epsilon:', i ,' Test Accuracy:', testacc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3682f28",
   "metadata": {},
   "source": [
    "### Carlini and Wagner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ef7787d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cw: 1  Test Accuracy: 100.0\n"
     ]
    }
   ],
   "source": [
    "# 3- C&W\n",
    "\n",
    "def cw(model, X,y,**kwargs):\n",
    "    \n",
    "    cw = torchattacks.CW(model,**kwargs)\n",
    "    adversarial_examples = cw(X, torch.argmax(y,axis=1))\n",
    "    \n",
    "    return adversarial_examples\n",
    "\n",
    "X , y = next(iter(test_loader))\n",
    "\n",
    "adversarial_examples= cw(model,X,y, c=1, kappa=0, steps=50, lr=0.01) \n",
    "\n",
    "preds=torch.softmax(model(adversarial_examples),axis=1)\n",
    "\n",
    "y_labels=torch.argmax(y,axis=1)\n",
    "pred_labels=torch.argmax(preds,axis=1)\n",
    "\n",
    "testacc=100 * torch.mean((pred_labels == y_labels).float()).item()\n",
    "print('cw:', 1 ,' Test Accuracy:', testacc)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5e10b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876a2c54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7583a5bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cad4434c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MulticlassClassification' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model_robust_PGD \u001b[38;5;241m=\u001b[39m \u001b[43mMulticlassClassification\u001b[49m(num_feature \u001b[38;5;241m=\u001b[39m in_f, num_class\u001b[38;5;241m=\u001b[39mout_f)\n\u001b[1;32m      2\u001b[0m model_robust_FGSM \u001b[38;5;241m=\u001b[39m MulticlassClassification(num_feature \u001b[38;5;241m=\u001b[39m in_f, num_class\u001b[38;5;241m=\u001b[39mout_f)\n\u001b[1;32m      3\u001b[0m model_robust_CW \u001b[38;5;241m=\u001b[39m MulticlassClassification(num_feature \u001b[38;5;241m=\u001b[39m in_f, num_class\u001b[38;5;241m=\u001b[39mout_f)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MulticlassClassification' is not defined"
     ]
    }
   ],
   "source": [
    "model_robust_PGD = BinaryClassification(num_feature = in_f, num_class=out_f)\n",
    "model_robust_FGSM = BinaryClassification(num_feature = in_f, num_class=out_f)\n",
    "model_robust_CW = BinaryClassification(num_feature = in_f, num_class=out_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90e921a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4f80fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_adv(loader, model,attack,**kwargs):\n",
    "    for X, y in loader:\n",
    "        \n",
    "        preds = model(X)\n",
    "\n",
    "        preds=torch.softmax(preds,axis=1)\n",
    "        \n",
    "        loss = loss_function(preds, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Adv\n",
    "        \n",
    "        adv = attack(model,X,y, **kwargs)\n",
    "\n",
    "\n",
    "        preds = model(adv)\n",
    "   \n",
    "\n",
    "        preds=torch.softmax(preds,axis=1)\n",
    "        \n",
    "        loss = loss_function(preds, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        y_labels=torch.argmax(y,axis=1)\n",
    "        pred_labels=torch.argmax(preds,axis=1)\n",
    "        \n",
    "        acc=100 * torch.mean((pred_labels == y_labels).float()).item()\n",
    "        \n",
    "    return loss,acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345da70f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33d97b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8c35c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PGD Training\n",
    "\n",
    "num_epochs = 500\n",
    "epsilon=0.05\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model_robust_PGD.parameters(), lr=0.006) #0.009\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "for epo in range(num_epochs):\n",
    "\n",
    "\n",
    "    loss,acc=epoch_adv(train_loader,model_robust_PGD,pgd,eps=epsilon, alpha=0.01, steps=10, random_start=False)\n",
    "\n",
    "    print(\"Epoch {}/{}, Loss: {:.3f}, Accuracy: {:.3f}\".format(epo+1,num_epochs, loss.item(), acc))\n",
    "\n",
    "\n",
    "\n",
    "    X , y = next(iter(test_loader))\n",
    "\n",
    "    adversarial_examples = pgd(model_robust_PGD,X,y, eps=epsilon, alpha=0.01, steps=10, random_start=False)\n",
    "\n",
    "    preds=torch.softmax(model_robust_PGD(adversarial_examples),axis=1)\n",
    "\n",
    "    y_labels=torch.argmax(y,axis=1)\n",
    "    pred_labels=torch.argmax(preds,axis=1)\n",
    "\n",
    "    testacc=100 * torch.mean((pred_labels == y_labels).float()).item()\n",
    "    print('epsilon:',epsilon,' Test Accuracy:', testacc)\n",
    "    \n",
    "    if epo==num_epochs:\n",
    "        \n",
    "        print(metrics.classification_report(y_labels+1, pred_labels+1))\n",
    "    \n",
    "    \n",
    "    X , y = next(iter(test_loader))\n",
    "\n",
    "\n",
    "    preds=torch.softmax(model_robust_PGD(X),axis=1)\n",
    "\n",
    "    y_labels=torch.argmax(y,axis=1)\n",
    "    pred_labels=torch.argmax(preds,axis=1)\n",
    "\n",
    "    testacc=100 * torch.mean((pred_labels == y_labels).float()).item()\n",
    "    print('epsilon:',0,' Test Accuracy:', testacc)\n",
    "    \n",
    "    if epo==num_epochs:\n",
    "        \n",
    "        print(metrics.classification_report(y_labels+1, pred_labels+1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b5d908",
   "metadata": {},
   "outputs": [],
   "source": [
    " X , y = next(iter(test_loader))\n",
    "\n",
    "adversarial_examples = pgd(model_robust_PGD,X,y, eps=epsilon, alpha=0.01, steps=10, random_start=False)\n",
    "\n",
    "preds=torch.softmax(model_robust_PGD(adversarial_examples),axis=1)\n",
    "\n",
    "y_labels=torch.argmax(y,axis=1)\n",
    "pred_labels=torch.argmax(preds,axis=1)\n",
    "\n",
    "testacc=100 * torch.mean((pred_labels == y_labels).float()).item()\n",
    "print('epsilon:',epsilon,' Test Accuracy:', testacc)\n",
    "\n",
    "\n",
    "print(metrics.classification_report(y_labels+1, pred_labels+1))\n",
    "    \n",
    "    \n",
    "X , y = next(iter(test_loader))\n",
    "\n",
    "\n",
    "preds=torch.softmax(model_robust_PGD(X),axis=1)\n",
    "\n",
    "y_labels=torch.argmax(y,axis=1)\n",
    "pred_labels=torch.argmax(preds,axis=1)\n",
    "\n",
    "testacc=100 * torch.mean((pred_labels == y_labels).float()).item()\n",
    "print('epsilon:',0,' Test Accuracy:', testacc)\n",
    "\n",
    "print(metrics.classification_report(y_labels+1, pred_labels+1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bf5911",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FGSM Training\n",
    "\n",
    "num_epochs = 500\n",
    "epsilon=0.05\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model_robust_FGSM.parameters(), lr=0.009) #0.009\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "for epo in range(num_epochs):\n",
    "\n",
    "\n",
    "    loss,acc=epoch_adv(train_loader,model_robust_FGSM,fgsm,eps=epsilon)\n",
    "\n",
    "    print(\"Epoch {}/{}, Loss: {:.3f}, Accuracy: {:.3f}\".format(epo+1,num_epochs, loss.item(), acc))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    X , y = next(iter(test_loader))\n",
    "\n",
    "    adversarial_examples = fgsm(model_robust_FGSM,X,y, eps=epsilon)\n",
    "\n",
    "    preds=torch.softmax(model_robust_FGSM(adversarial_examples),axis=1)\n",
    "\n",
    "    y_labels=torch.argmax(y,axis=1)\n",
    "    pred_labels=torch.argmax(preds,axis=1)\n",
    "\n",
    "    testacc=100 * torch.mean((pred_labels == y_labels).float()).item()\n",
    "    print('epsilon:',epsilon,' Test Accuracy:', testacc)\n",
    "    \n",
    "        \n",
    "    if epo==num_epochs-1:\n",
    "        \n",
    "        print(metrics.classification_report(y_labels+1, pred_labels+1))\n",
    "    \n",
    "    \n",
    "    X , y = next(iter(test_loader))\n",
    "\n",
    "\n",
    "    preds=torch.softmax(model_robust_FGSM(X),axis=1)\n",
    "\n",
    "    y_labels=torch.argmax(y,axis=1)\n",
    "    pred_labels=torch.argmax(preds,axis=1)\n",
    "\n",
    "    testacc=100 * torch.mean((pred_labels == y_labels).float()).item()\n",
    "    print('epsilon:',0,' Test Accuracy:', testacc)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    if epo==num_epochs-1:\n",
    "        \n",
    "        print(metrics.classification_report(y_labels+1, pred_labels+1))\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9964bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CW Training\n",
    "\n",
    "num_epochs = 500\n",
    "c=1\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model_robust_CW.parameters(), lr=0.006) #0.009\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "for epo in range(num_epochs):\n",
    "\n",
    "\n",
    "    loss,acc=epoch_adv(train_loader,model_robust_CW,cw,c=c, kappa=0, steps=50, lr=0.01) \n",
    "\n",
    "    print(\"Epoch {}/{}, Loss: {:.3f}, Accuracy: {:.3f}\".format(epo+1,num_epochs, loss.item(), acc))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c61666d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X , y = next(iter(test_loader))\n",
    "\n",
    "adversarial_examples = cw(model_robust_CW,X,y,c=1, kappa=0, steps=50, lr=0.01) \n",
    "\n",
    "preds=torch.softmax(model_robust_CW(adversarial_examples),axis=1)\n",
    "\n",
    "y_labels=torch.argmax(y,axis=1)\n",
    "pred_labels=torch.argmax(preds,axis=1)\n",
    "\n",
    "testacc=100 * torch.mean((pred_labels == y_labels).float()).item()\n",
    "print('c:',c,' Test Accuracy:', testacc)\n",
    "\n",
    "\n",
    "\n",
    "print(metrics.classification_report(y_labels+1, pred_labels+1))\n",
    "\n",
    "\n",
    "X , y = next(iter(test_loader))\n",
    "\n",
    "\n",
    "preds=torch.softmax(model_robust_CW(X),axis=1)\n",
    "\n",
    "y_labels=torch.argmax(y,axis=1)\n",
    "pred_labels=torch.argmax(preds,axis=1)\n",
    "\n",
    "testacc=100 * torch.mean((pred_labels == y_labels).float()).item()\n",
    "print('c',c,' Test Accuracy:', testacc)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(metrics.classification_report(y_labels+1, pred_labels+1))\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed28f9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define your model as usual\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc = nn.Linear(10, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# Initialize the model and set it to evaluation mode\n",
    "model_robust_CW = BinaryClassification(num_feature = in_f, num_class=out_f)\n",
    "model.eval()\n",
    "\n",
    "# Define a temperature value to use during distillation\n",
    "T = 4\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.KLDivLoss(reduction='batchmean')\n",
    "\n",
    "# Define the inputs and targets\n",
    "inputs = torch.randn(64, 10)\n",
    "targets = torch.randn(64, 10)\n",
    "\n",
    "# Get the logits from the model\n",
    "logits = model(inputs)\n",
    "\n",
    "# Scale the logits using the temperature\n",
    "logits = logits / T\n",
    "\n",
    "# Calculate the loss\n",
    "loss = criterion(torch.log_softmax(logits, dim=1), torch.softmax(targets / T, dim=1))\n",
    "\n",
    "# Use backpropagation to update the model's parameters\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c61efa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e43579e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
